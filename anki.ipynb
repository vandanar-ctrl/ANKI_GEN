{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304bbdfe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install -y zstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058ab2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3498e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b269ff8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# BASE_DIR = \"/content/drive/MyDrive/anki_mindmap_LLM\"\n",
    "\n",
    "# OLLAMA_DIR = f\"{BASE_DIR}/ollama\"\n",
    "# MODELS_DIR = f\"{OLLAMA_DIR}/models\"\n",
    "\n",
    "# # os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# print(\"✅ Ollama model directory ready\")\n",
    "# print(\"MODELS:\", MODELS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6361b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%env OLLAMA_MODELS=/content/drive/MyDrive/anki_mindmap_LLM/ollama/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214344a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!nohup /usr/local/bin/ollama serve > ollama.log 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cde5da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!ollama list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce47ec1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install bloom-filter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d83771",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"/content/drive/MyDrive/anki_mindmap_LLM/input/metadata.csv\")\n",
    "\n",
    "print(\"Exists:\", path.exists())\n",
    "print(\"Is file:\", path.is_file())\n",
    "print(\"Parent exists:\", path.parent.exists())\n",
    "print(\"Parent contents:\", list(path.parent.glob(\"*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1d8a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: CONFIGURATION & CONSTANTS (FIXED VERSION)\n",
    "# ============================================================\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Optional, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "from threading import Lock\n",
    "from functools import lru_cache\n",
    "from types import MappingProxyType\n",
    "\n",
    "# Setup logging before anything else\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('/tmp/anki_pipeline.log')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"anki-pipeline\")\n",
    "\n",
    "# Optional bloom filter (graceful degradation if not available)\n",
    "try:\n",
    "    from bloom_filter2 import BloomFilter\n",
    "    BLOOM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    BLOOM_AVAILABLE = False\n",
    "    logger.warning(\"bloom_filter2 not installed - using set-based deduplication\")\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG - IMMUTABLE\n",
    "# ============================================================\n",
    "def load_config():\n",
    "    \"\"\"Load configuration with proper validation\"\"\"\n",
    "    # Determine CSV location\n",
    "    CSV_LOCATIONS = [\n",
    "        \"/content/drive/MyDrive/anki_mindmap_LLM/input/metadata.csv\",\n",
    "        \"./metadata.csv\",\n",
    "        os.getenv(\"ANKI_CSV_PATH\", \"\"),\n",
    "    ]\n",
    "    \n",
    "    CSV_FILE = None\n",
    "    for loc in CSV_LOCATIONS:\n",
    "        if loc and Path(loc).exists():\n",
    "            CSV_FILE = loc\n",
    "            break\n",
    "    \n",
    "    if not CSV_FILE:\n",
    "        CSV_FILE = CSV_LOCATIONS[0]\n",
    "    \n",
    "    # Determine base directory\n",
    "    BASE_DIR = Path(os.getenv(\"ANKI_BASE_DIR\", \"/content/drive/MyDrive/anki_mindmap_LLM\"))\n",
    "    \n",
    "    config = {\n",
    "        # Core paths\n",
    "        \"OLLAMA_URL\": \"http://127.0.0.1:11434\",\n",
    "        \"CSV_FILE\": CSV_FILE,\n",
    "        \"BASE_DIR\": BASE_DIR,\n",
    "        \"OUT_DIR\": BASE_DIR / \"output\",\n",
    "        \n",
    "        # Processing limits\n",
    "        \"BATCH_SIZE\": 5,\n",
    "        \"MAX_WORKERS\": 4,\n",
    "        \"MAX_REELS\": 1000,\n",
    "        \"CONFIDENCE_THRESHOLD\": 0.65,\n",
    "        \"FINGERPRINT_BATCH_SIZE\": 100,\n",
    "        \"CACHE_VERSION\": \"v4_fixed\",\n",
    "        \n",
    "        # Circuit breaker settings\n",
    "        \"CIRCUIT_BREAKER_THRESHOLD\": 5,\n",
    "        \"CIRCUIT_BREAKER_TIMEOUT\": 60,\n",
    "        \n",
    "        # PRODUCTION SAFETY SWITCHES\n",
    "        \"ENABLE_ENRICHMENT\": True,\n",
    "        \"ENABLE_REJECTION_LEARNING\": True,\n",
    "        \"ENABLE_TRADEOFFS\": True,\n",
    "        \"ENABLE_PROMPT_ROUTING\": True,\n",
    "        \"ENABLE_FOUNDATION_EXPANSION\": True,\n",
    "        \n",
    "        # PHASE 1-3: ADVANCED CONTENT PROCESSING\n",
    "        \"ENABLE_CONTENT_FILTERING\": True,\n",
    "        \"ENABLE_TRANSCRIPT_NORMALIZATION\": True,\n",
    "        \"ENABLE_HYBRID_ROUTING\": True,\n",
    "        \n",
    "        # ENRICHMENT CONTROLS\n",
    "        \"MAX_ENRICHMENTS_PER_CONCEPT\": {\n",
    "            \"foundation\": 1,\n",
    "            \"intermediate\": 2,\n",
    "            \"advanced\": 2\n",
    "        },\n",
    "        \"MAX_RETRIES\": 3,\n",
    "        \n",
    "        # COMPLETION THRESHOLDS\n",
    "        \"MIN_CARDS_FOR_FULL\": 3,\n",
    "        \"MIN_CARDS_FOR_PARTIAL\": 2,\n",
    "        \n",
    "        # NORMALIZATION\n",
    "        \"NORMALIZE_TECH_SCORES\": True,\n",
    "        \n",
    "        # Content density thresholds\n",
    "        \"DENSE_CONTENT_MIN_WORDS\": 150,\n",
    "        \"LIGHT_CONTENT_MAX_WORDS\": 100,\n",
    "        \n",
    "        # Validation\n",
    "        \"MIN_TRANSCRIPT_LENGTH\": 80,\n",
    "        \"MIN_CATEGORY_CONFIDENCE\": 70,\n",
    "    }\n",
    "    \n",
    "    # Create directories\n",
    "    config[\"OUT_DIR\"].mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create cache directory\n",
    "    CACHE_DIR = config[\"OUT_DIR\"] / \"cache\"\n",
    "    CACHE_DIR.mkdir(exist_ok=True)\n",
    "    config[\"CACHE_DIR\"] = CACHE_DIR\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Load and make config immutable\n",
    "_CONFIG = load_config()\n",
    "CONFIG = MappingProxyType(_CONFIG)\n",
    "logger.info(f\"Loaded configuration from {CONFIG['CSV_FILE']}\")\n",
    "\n",
    "# File paths\n",
    "PROGRESS_FILE = CONFIG[\"OUT_DIR\"] / \"processed.txt\"\n",
    "CARD_FINGERPRINTS_FILE = CONFIG[\"OUT_DIR\"] / \"card_fingerprints.json\"\n",
    "BLOOM_FILE = CONFIG[\"OUT_DIR\"] / \"card_bloom.bin\"\n",
    "REJECTION_MEMORY_FILE = CONFIG[\"OUT_DIR\"] / \"rejection_memory.json\"\n",
    "PROMPT_VERSION_FILE = CONFIG[\"OUT_DIR\"] / \"prompt_version_stats.json\"\n",
    "ROUTING_METRICS_FILE = CONFIG[\"OUT_DIR\"] / \"routing_metrics.json\"\n",
    "TERMINAL_REJECTIONS_FILE = CONFIG[\"OUT_DIR\"] / \"terminal_rejections.json\"\n",
    "CONFIDENCE_CALIBRATION_FILE = CONFIG[\"OUT_DIR\"] / \"confidence_calibration.json\"\n",
    "ERROR_LOG_FILE = CONFIG[\"OUT_DIR\"] / \"error_log.json\"\n",
    "\n",
    "# ============================================================\n",
    "# CIRCUIT BREAKER PATTERN\n",
    "# ============================================================\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Circuit breaker to prevent cascade failures\"\"\"\n",
    "    \n",
    "    def __init__(self, name, failure_threshold=5, reset_timeout=60):\n",
    "        self.name = name\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.reset_timeout = reset_timeout\n",
    "        self.failures = 0\n",
    "        self.last_failure_time = 0\n",
    "        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n",
    "        self.lock = Lock()\n",
    "    \n",
    "    def is_open(self):\n",
    "        \"\"\"Check if circuit breaker is open\"\"\"\n",
    "        with self.lock:\n",
    "            if self.state == \"OPEN\":\n",
    "                # Check if timeout has passed\n",
    "                if time.time() - self.last_failure_time > self.reset_timeout:\n",
    "                    self.state = \"HALF_OPEN\"\n",
    "                    logger.info(f\"Circuit breaker {self.name} moving to HALF_OPEN\")\n",
    "                    return False\n",
    "                return True\n",
    "            return False\n",
    "    \n",
    "    def record_failure(self):\n",
    "        \"\"\"Record a failure and potentially open the circuit\"\"\"\n",
    "        with self.lock:\n",
    "            self.failures += 1\n",
    "            self.last_failure_time = time.time()\n",
    "            \n",
    "            if self.failures >= self.failure_threshold:\n",
    "                if self.state != \"OPEN\":\n",
    "                    self.state = \"OPEN\"\n",
    "                    logger.warning(f\"Circuit breaker {self.name} OPENED after {self.failures} failures\")\n",
    "    \n",
    "    def record_success(self):\n",
    "        \"\"\"Record a success and potentially close the circuit\"\"\"\n",
    "        with self.lock:\n",
    "            if self.state == \"HALF_OPEN\":\n",
    "                self.state = \"CLOSED\"\n",
    "                self.failures = 0\n",
    "                logger.info(f\"Circuit breaker {self.name} CLOSED after successful trial\")\n",
    "            elif self.state == \"CLOSED\":\n",
    "                # Decay failures slowly\n",
    "                self.failures = max(0, self.failures - 1)\n",
    "    \n",
    "    def call(self, func, *args, **kwargs):\n",
    "        \"\"\"Wrap a function call with circuit breaker protection\"\"\"\n",
    "        if self.is_open():\n",
    "            raise RuntimeError(f\"Circuit breaker {self.name} is OPEN\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            self.record_success()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.record_failure()\n",
    "            raise\n",
    "\n",
    "# Initialize circuit breakers\n",
    "OLLAMA_CIRCUIT_BREAKER = CircuitBreaker(\n",
    "    \"ollama\",\n",
    "    failure_threshold=CONFIG[\"CIRCUIT_BREAKER_THRESHOLD\"],\n",
    "    reset_timeout=CONFIG[\"CIRCUIT_BREAKER_TIMEOUT\"]\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# ERROR TRACKING\n",
    "# ============================================================\n",
    "class ErrorTracker:\n",
    "    \"\"\"Track and categorize errors for observability\"\"\"\n",
    "    \n",
    "    def __init__(self, error_file: Path):\n",
    "        self.error_file = error_file\n",
    "        self.errors = []\n",
    "        self.error_counts = defaultdict(int)\n",
    "        self.lock = Lock()\n",
    "        self._load()\n",
    "    \n",
    "    def _load(self):\n",
    "        \"\"\"Load existing errors\"\"\"\n",
    "        if self.error_file.exists():\n",
    "            try:\n",
    "                with open(self.error_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    self.errors = data.get(\"errors\", [])\n",
    "                    self.error_counts = defaultdict(int, data.get(\"counts\", {}))\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to load error tracker: {e}\")\n",
    "    \n",
    "    def record(self, error_type: str, message: str, context: Dict = None):\n",
    "        \"\"\"Record an error\"\"\"\n",
    "        with self.lock:\n",
    "            error_entry = {\n",
    "                \"type\": error_type,\n",
    "                \"message\": message,\n",
    "                \"context\": context or {},\n",
    "                \"timestamp\": time.time(),\n",
    "                \"iso_timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n",
    "            }\n",
    "            \n",
    "            self.errors.append(error_entry)\n",
    "            self.error_counts[error_type] += 1\n",
    "            \n",
    "            # Keep only last 1000 errors\n",
    "            if len(self.errors) > 1000:\n",
    "                self.errors = self.errors[-1000:]\n",
    "            \n",
    "            # Periodic save\n",
    "            if len(self.errors) % 50 == 0:\n",
    "                self.save()\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Save errors to disk\"\"\"\n",
    "        with self.lock:\n",
    "            try:\n",
    "                with open(self.error_file, 'w') as f:\n",
    "                    json.dump({\n",
    "                        \"errors\": self.errors[-500:],  # Keep only recent errors\n",
    "                        \"counts\": dict(self.error_counts),\n",
    "                        \"total_errors\": len(self.errors)\n",
    "                    }, f, indent=2)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save error tracker: {e}\")\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get error statistics\"\"\"\n",
    "        with self.lock:\n",
    "            return {\n",
    "                \"total_errors\": len(self.errors),\n",
    "                \"error_counts\": dict(self.error_counts),\n",
    "                \"recent_errors\": self.errors[-20:] if self.errors else []\n",
    "            }\n",
    "\n",
    "# Initialize error tracker\n",
    "error_tracker = ErrorTracker(ERROR_LOG_FILE)\n",
    "\n",
    "# ============================================================\n",
    "# ATOMIC FILE OPERATIONS\n",
    "# ============================================================\n",
    "def atomic_write(data, filepath: Path):\n",
    "    \"\"\"Write data atomically to prevent corruption\"\"\"\n",
    "    import tempfile\n",
    "    temp_path = Path(str(filepath) + '.tmp')\n",
    "    try:\n",
    "        with open(temp_path, 'w') as f:\n",
    "            if isinstance(data, (dict, list)):\n",
    "                json.dump(data, f, indent=2)\n",
    "            else:\n",
    "                f.write(str(data))\n",
    "        temp_path.replace(filepath)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Atomic write failed: {e}\")\n",
    "        # Clean up temp file\n",
    "        if temp_path.exists():\n",
    "            temp_path.unlink()\n",
    "        raise\n",
    "\n",
    "def atomic_read(filepath: Path, default=None):\n",
    "    \"\"\"Read data with corruption recovery\"\"\"\n",
    "    if not filepath.exists():\n",
    "        return default\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            if filepath.suffix == '.json':\n",
    "                return json.load(f)\n",
    "            else:\n",
    "                return f.read()\n",
    "    except (json.JSONDecodeError, IOError) as e:\n",
    "        logger.warning(f\"File {filepath} corrupted, attempting recovery: {e}\")\n",
    "        # Try to backup corrupted file\n",
    "        backup_path = filepath.with_suffix('.corrupted')\n",
    "        try:\n",
    "            filepath.rename(backup_path)\n",
    "        except:\n",
    "            pass\n",
    "        return default\n",
    "\n",
    "# ============================================================\n",
    "# INITIALIZATION STATUS\n",
    "# ============================================================\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(\"ANKI GENERATION PIPELINE - INITIALIZED\")\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(f\"Output directory: {CONFIG['OUT_DIR']}\")\n",
    "logger.info(f\"CSV file: {CONFIG['CSV_FILE']}\")\n",
    "logger.info(f\"Max reels: {CONFIG['MAX_REELS']}\")\n",
    "logger.info(f\"Circuit breaker: {CONFIG['CIRCUIT_BREAKER_THRESHOLD']} failures / {CONFIG['CIRCUIT_BREAKER_TIMEOUT']}s timeout\")\n",
    "logger.info(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aecee9a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: DATA TYPES & SCHEMAS\n",
    "# ============================================================\n",
    "class CompletionState(Enum):\n",
    "    FULL = \"full\"\n",
    "    PARTIAL = \"partial\"\n",
    "    INCOMPLETE = \"incomplete\"\n",
    "\n",
    "class RejectionType(Enum):\n",
    "    SEMANTIC = \"rejected_semantic\"\n",
    "    STRUCTURAL = \"rejected_structural\"\n",
    "    MECHANICAL = \"error_mechanical\"\n",
    "\n",
    "class ContentDensity(Enum):\n",
    "    DENSE = \"dense\"\n",
    "    LIGHT = \"light\"\n",
    "    SKIP = \"skip\"\n",
    "\n",
    "class PromptStrategy(Enum):\n",
    "    STRICT_ADVANCED = \"A_STRICT\"\n",
    "    FOUNDATION_AWARE = \"B_FOUNDATION\"\n",
    "    DSA_FOCUSED = \"C_DSA\"\n",
    "\n",
    "@dataclass\n",
    "class QualityDimensions:\n",
    "    correctness_score: float\n",
    "    richness_score: float\n",
    "    combined_score: float\n",
    "\n",
    "    @classmethod\n",
    "    def calculate(cls, atoms: Dict, cards: List[Dict]):\n",
    "        has_definition = bool(atoms.get(\"definition\"))\n",
    "        has_tech_points = len(atoms.get(\"technical_points\", [])) >= 3\n",
    "        has_solutions = len(atoms.get(\"solutions\", [])) >= 1\n",
    "\n",
    "        correctness = (\n",
    "            (0.4 if has_definition else 0) +\n",
    "            (0.4 if has_tech_points else 0) +\n",
    "            (0.2 if has_solutions else 0)\n",
    "        )\n",
    "\n",
    "        card_count = len(cards)\n",
    "        has_related = len(atoms.get(\"related_concepts\", [])) > 0\n",
    "        has_tradeoffs = atoms.get(\"has_tradeoffs\", False)\n",
    "\n",
    "        richness = (\n",
    "            min(card_count / 3, 0.5) +\n",
    "            (0.3 if has_related else 0) +\n",
    "            (0.2 if has_tradeoffs else 0)\n",
    "        )\n",
    "        richness = min(richness, 1.0)\n",
    "\n",
    "        combined = correctness * 0.6 + richness * 0.4\n",
    "\n",
    "        return cls(\n",
    "            correctness_score=round(correctness, 2),\n",
    "            richness_score=round(richness, 2),\n",
    "            combined_score=round(combined, 2)\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    name: str\n",
    "    gpu_layers: int = -1\n",
    "    temperature: float = 0.1\n",
    "    num_predict: int = 2000\n",
    "    top_p: float = 0.9\n",
    "\n",
    "class BaseSchema:\n",
    "    required: set = set()\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, data: dict) -> bool:\n",
    "        return isinstance(data, dict) and cls.required.issubset(data.keys())\n",
    "\n",
    "class AtomsSchema(BaseSchema):\n",
    "    required = {\n",
    "        \"concept\", \"category\", \"definition\",\n",
    "        \"technical_points\", \"solutions\", \"impact\", \"has_tradeoffs\",\n",
    "    }\n",
    "\n",
    "class BasicCardSchema(BaseSchema):\n",
    "    required = {\"type\", \"front\", \"back\"}\n",
    "\n",
    "class ClozeCardSchema(BaseSchema):\n",
    "    required = {\"type\", \"cloze\"}\n",
    "\n",
    "class TradeoffCardSchema(BaseSchema):\n",
    "    required = {\"type\", \"tradeoffs\"}\n",
    "\n",
    "class CardsContainerSchema(BaseSchema):\n",
    "    required = {\"cards\"}\n",
    "\n",
    "# ============================================================\n",
    "# GLOBAL STATE (Minimal)\n",
    "# ============================================================\n",
    "ROUTING_METRICS = defaultdict(int)\n",
    "ROUTING_COUNTS = defaultdict(int)\n",
    "MODEL_CAPABILITY_CACHE = {}\n",
    "MODEL_CAPABILITY_LOCK = Lock()\n",
    "PROMPT_VERSION_STATS = {}\n",
    "PROMPT_VERSION_LOCK = Lock()\n",
    "CONFIDENCE_CALIBRATION = {\n",
    "    \"buckets\": {\n",
    "        \"0.5-0.6\": {\"total\": 0, \"accepted\": 0},\n",
    "        \"0.6-0.7\": {\"total\": 0, \"accepted\": 0},\n",
    "        \"0.7-0.8\": {\"total\": 0, \"accepted\": 0},\n",
    "        \"0.8-0.9\": {\"total\": 0, \"accepted\": 0},\n",
    "        \"0.9-1.0\": {\"total\": 0, \"accepted\": 0}\n",
    "    }\n",
    "}\n",
    "\n",
    "ENRICHMENT_BUDGET = defaultdict(int)\n",
    "ENRICHMENT_TIMESTAMPS = defaultdict(float)\n",
    "ENRICHMENT_BUDGET_LOCK = Lock()\n",
    "ENRICHMENT_BUDGET_RESET_DAYS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc333ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: CONTENT PROCESSING & CLASSIFICATION\n",
    "# ============================================================\n",
    "\n",
    "# Mechanism markers for deep content detection\n",
    "MECHANISM_MARKERS = [\n",
    "    \"contract\", \"invariant\", \"guarantee\", \"violates\", \"breaks\", \"ensures\",\n",
    "    \"depends on\", \"requires\", \"only if\", \"undefined behavior\", \"happens-before\",\n",
    "    \"race condition\", \"memory model\", \"visibility\", \"ordering\", \"consistency\",\n",
    "    \"semantics\", \"specification\", \"constraint\", \"precondition\", \"postcondition\"\n",
    "]\n",
    "\n",
    "# Topic classification configuration\n",
    "TOPIC_CLASSES = {\n",
    "    \"foundation\": {\n",
    "        \"keywords\": [\n",
    "            \"immutability\", \"string\", \"array\", \"oops\", \"collection\",\n",
    "            \"hashmap\", \"equals\", \"hashcode\", \"sorting\", \"basics\",\n",
    "            \"fundamentals\", \"introduction\", \"inheritance\", \"polymorphism\",\n",
    "            \"encapsulation\", \"abstraction\", \"list\", \"set\", \"queue\"\n",
    "        ],\n",
    "        \"threshold_adjustment\": -3,\n",
    "        \"expected_depth\": \"intermediate\",\n",
    "        \"expected_cards\": 2\n",
    "    },\n",
    "    \"intermediate\": {\n",
    "        \"keywords\": [\n",
    "            \"concurrency\", \"thread\", \"lock\", \"synchronization\", \"volatile\",\n",
    "            \"atomic\", \"concurrent\", \"deadlock\", \"race condition\",\n",
    "            \"memory model\", \"jvm\", \"garbage collection\", \"classloader\"\n",
    "        ],\n",
    "        \"threshold_adjustment\": -1,\n",
    "        \"expected_depth\": \"deep\",\n",
    "        \"expected_cards\": 3\n",
    "    },\n",
    "    \"advanced\": {\n",
    "        \"keywords\": [\n",
    "            \"distributed\", \"saga\", \"circuit breaker\", \"event sourcing\",\n",
    "            \"cqrs\", \"microservice\", \"kubernetes\", \"docker\", \"kafka\",\n",
    "            \"consistency model\", \"partition tolerance\", \"cap theorem\"\n",
    "        ],\n",
    "        \"threshold_adjustment\": 0,\n",
    "        \"expected_depth\": \"very_deep\",\n",
    "        \"expected_cards\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "# Technical keywords for scoring\n",
    "TECHNICAL_KEYWORDS = {\n",
    "    \"java\": [\n",
    "        \"heap\", \"stack\", \"garbage collection\", \"jvm\", \"bytecode\",\n",
    "        \"classloader\", \"reflection\", \"synchronized\", \"volatile\",\n",
    "        \"thread\", \"immutable\", \"serialization\", \"generics\"\n",
    "    ],\n",
    "    \"spring\": [\n",
    "        \"dependency injection\", \"bean\", \"autowired\", \"aop\",\n",
    "        \"transactional\", \"repository\", \"service\", \"controller\",\n",
    "        \"configuration\", \"component scan\"\n",
    "    ],\n",
    "    \"microservices\": [\n",
    "        \"saga\", \"event sourcing\", \"cqrs\", \"api gateway\",\n",
    "        \"service mesh\", \"circuit breaker\", \"bulkhead\", \"rate limiting\",\n",
    "        \"idempotency\", \"distributed transaction\"\n",
    "    ],\n",
    "    \"algorithms\": [\n",
    "        \"time complexity\", \"space complexity\", \"big o\", \"recursion\",\n",
    "        \"dynamic programming\", \"backtracking\", \"greedy\", \"divide and conquer\"\n",
    "    ],\n",
    "    \"system_design\": [\n",
    "        \"scalability\", \"availability\", \"consistency\", \"partition tolerance\",\n",
    "        \"load balancer\", \"caching\", \"sharding\", \"replication\",\n",
    "        \"eventual consistency\", \"cap theorem\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Foundation-specific keywords for better scoring\n",
    "FOUNDATION_ENHANCEMENT_KEYWORDS = [\n",
    "    \"string\", \"array\", \"list\", \"map\", \"set\", \"queue\", \"stack\",\n",
    "    \"equals\", \"hashcode\", \"immutable\", \"mutable\", \"inheritance\",\n",
    "    \"polymorphism\", \"encapsulation\", \"abstraction\", \"interface\",\n",
    "    \"abstract class\", \"constructor\", \"static\", \"final\", \"volatile\",\n",
    "    \"transient\", \"synchronized\", \"exception\", \"try\", \"catch\", \"finally\",\n",
    "    \"stream\", \"lambda\", \"functional interface\", \"optional\", \"generic\"\n",
    "]\n",
    "\n",
    "def classify_topic(caption: str, category: str, transcript: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Classify topic depth based on keywords and context.\n",
    "    Returns: 'foundation', 'intermediate', or 'advanced'\n",
    "    \"\"\"\n",
    "    text = f\"{caption} {transcript}\".lower()\n",
    "\n",
    "    # Check each class in reverse order (advanced first)\n",
    "    for topic_class, config in reversed(list(TOPIC_CLASSES.items())):\n",
    "        keywords = config[\"keywords\"]\n",
    "        if any(kw in text for kw in keywords):\n",
    "            return topic_class\n",
    "\n",
    "    # Enhanced: Check for decision/comparison/tradeoff signals\n",
    "    tradeoff_signals = [\"vs\", \" vs \", \"versus\", \"or \", \"instead\", \"trade-off\", \"tradeoff\",\n",
    "                       \"compare\", \"comparison\", \"difference between\", \"when to\", \"choose\"]\n",
    "    decision_signals = [\"decide\", \"decision\", \"which\", \"what if\", \"scenario\", \"use case\",\n",
    "                       \"depends on\", \"context\", \"situation\"]\n",
    "\n",
    "    has_tradeoff = any(signal in text for signal in tradeoff_signals)\n",
    "    has_decision = any(signal in text for signal in decision_signals)\n",
    "\n",
    "    # Count technical depth markers\n",
    "    depth_markers = [\"internal\", \"mechanism\", \"how it works\", \"under the hood\",\n",
    "                    \"implementation\", \"architecture\", \"design pattern\", \"best practice\"]\n",
    "    depth_count = sum(1 for marker in depth_markers if marker in text)\n",
    "\n",
    "    # Don't default to foundation - use multiple signals\n",
    "    transcript_len = len(transcript.strip())\n",
    "\n",
    "    # Advanced signals: long transcript + tradeoffs/decisions + depth\n",
    "    if transcript_len > 400 and (has_tradeoff or depth_count >= 2):\n",
    "        return \"advanced\"\n",
    "\n",
    "    # Intermediate signals: medium length + decisions OR good depth\n",
    "    if transcript_len > 200 and (has_decision or has_tradeoff or depth_count >= 1):\n",
    "        return \"intermediate\"\n",
    "\n",
    "    # Long transcripts without keywords default to intermediate (not foundation)\n",
    "    if transcript_len > 500:\n",
    "        return \"intermediate\"\n",
    "    elif transcript_len > 250:\n",
    "        return \"intermediate\"\n",
    "    else:\n",
    "        return \"foundation\"\n",
    "\n",
    "def classify_content_density(caption: str, transcript: str, category: str = \"\") -> ContentDensity:\n",
    "    \"\"\"\n",
    "    PHASE 3: Classify content density for multi-track routing.\n",
    "    \n",
    "    Returns:\n",
    "    - DENSE: Tutorial/problem-solving with concrete examples → Full pipeline\n",
    "    - LIGHT: Foundation/motivational content → Reference-only cards  \n",
    "    - SKIP: Pure CTA/promotional → Don't process\n",
    "    \"\"\"\n",
    "    text = f\"{caption} {transcript}\".lower()\n",
    "    word_count = len(transcript.split())\n",
    "    \n",
    "    # Dense indicators (tutorial/problem-solving content)\n",
    "    dense_signals = {\n",
    "        \"code_present\": any(marker in text for marker in [\n",
    "            \"code\", \"function\", \"method\", \"class\", \"variable\", \n",
    "            \"algorithm\", \"implementation\", \"syntax\", \"example\"\n",
    "        ]),\n",
    "        \"problem_solving\": any(marker in text for marker in [\n",
    "            \"question\", \"problem\", \"solve\", \"solution\", \"approach\",\n",
    "            \"step 1\", \"step 2\", \"algorithm\", \"complexity\"\n",
    "        ]),\n",
    "        \"concrete_example\": any(marker in text for marker in [\n",
    "            \"for example\", \"let's say\", \"consider\", \"here is\",\n",
    "            \"output\", \"result\", \"returns\"\n",
    "        ]),\n",
    "        \"mechanism\": any(marker in text for marker in [\n",
    "            \"how it works\", \"internally\", \"mechanism\", \"under the hood\",\n",
    "            \"behind the scenes\", \"what happens\"\n",
    "        ]),\n",
    "        \"structured\": \"step\" in text and word_count > 150,\n",
    "        \"long_form\": word_count > 300\n",
    "    }\n",
    "    \n",
    "    # Light indicators (overview/motivational content)\n",
    "    light_signals = {\n",
    "        \"overview\": any(marker in text for marker in [\n",
    "            \"introduction\", \"overview\", \"basics\", \"fundamentals\",\n",
    "            \"what is\", \"definition\"\n",
    "        ]),\n",
    "        \"motivational\": any(marker in text for marker in [\n",
    "            \"you must know\", \"important to\", \"should learn\",\n",
    "            \"every developer\", \"trust me\"\n",
    "        ]),\n",
    "        \"list_based\": any(marker in text for marker in [\n",
    "            \"top 10\", \"top 5\", \"things to\", \"tips\", \"must know\"\n",
    "        ]),\n",
    "        \"short_form\": word_count < 150\n",
    "    }\n",
    "    \n",
    "    # Calculate density score\n",
    "    dense_score = sum(dense_signals.values())\n",
    "    light_score = sum(light_signals.values())\n",
    "    \n",
    "    # Decision logic\n",
    "    if dense_score >= 3:\n",
    "        return ContentDensity.DENSE\n",
    "    elif dense_score >= 2 and light_score <= 1:\n",
    "        return ContentDensity.DENSE\n",
    "    elif light_score >= 2 or word_count < 100:\n",
    "        return ContentDensity.LIGHT\n",
    "    else:\n",
    "        # Default: if unclear, treat as LIGHT (safer)\n",
    "        return ContentDensity.LIGHT\n",
    "\n",
    "def normalize_learning_key(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Robust caption normalization to prevent memory fragmentation.\n",
    "    \n",
    "    Without this, memory fragments across:\n",
    "    - punctuation variants (\"HashMap!\" vs \"HashMap\")\n",
    "    - emoji presence\n",
    "    - trailing hashtags\n",
    "    - \"Part 1 / Part 2\" suffixes\n",
    "    \n",
    "    This ensures learning convergence.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'#\\w+', '', text)              # Remove hashtags\n",
    "    text = re.sub(r'\\bpart\\s*\\d+\\b', '', text, flags=re.IGNORECASE)  # Remove \"Part 1\", \"Part 2\"\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)          # Remove punctuation, keep words and spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()      # Normalize whitespace\n",
    "    return text\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def technical_score(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Calculate technical density score (0-10).\n",
    "    Cached with LRU for 50k+ reel nightly processing.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        text = json.dumps(text, ensure_ascii=False)\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    score = 0\n",
    "\n",
    "    # Keyword matching (base score)\n",
    "    for category, keywords in TECHNICAL_KEYWORDS.items():\n",
    "        matches = sum(1 for kw in keywords if kw in text_lower)\n",
    "        score += min(matches, 3)\n",
    "\n",
    "    # Enhanced: Foundation-specific keyword bonus\n",
    "    foundation_matches = sum(1 for kw in FOUNDATION_ENHANCEMENT_KEYWORDS if kw in text_lower)\n",
    "    score += min(foundation_matches, 4)  # Up to +4 for foundation content\n",
    "\n",
    "    # Mechanism marker bonus\n",
    "    mechanism_count = sum(1 for marker in MECHANISM_MARKERS if marker in text_lower)\n",
    "    if mechanism_count > 0:\n",
    "        score += min(mechanism_count * 2, 4)  # Up to +4 for deep content\n",
    "\n",
    "    # Length normalization\n",
    "    word_count = len(text.split())\n",
    "    if word_count < 50:\n",
    "        score = score * 0.7\n",
    "    elif word_count > 200:\n",
    "        score = score * 1.2\n",
    "\n",
    "    return min(max(int(score), 1), 10)  # Ensure at least 1, max 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e03e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: MEMORY & LEARNING SYSTEMS\n",
    "# ============================================================\n",
    "import pickle\n",
    "\n",
    "class HybridDuplicateDetector:\n",
    "    \"\"\"\n",
    "    Hybrid duplicate detection:\n",
    "    - Bloom filter for O(1) probabilistic check\n",
    "    - Exact set for final verification\n",
    "    - Batch persistence\n",
    "    \"\"\"\n",
    "    def __init__(self, fingerprints_file: Path, bloom_file: Path):\n",
    "        self.fingerprints_file = fingerprints_file\n",
    "        self.bloom_file = bloom_file\n",
    "        self.lock = Lock()\n",
    "\n",
    "        self.fingerprints: Set[str] = self._load_fingerprints()\n",
    "\n",
    "        if BLOOM_AVAILABLE:\n",
    "            self.bloom = self._load_bloom()\n",
    "        else:\n",
    "            self.bloom = None\n",
    "\n",
    "        self._dirty = False\n",
    "        self._dirty_count = 0\n",
    "\n",
    "    def _load_fingerprints(self) -> Set[str]:\n",
    "        if self.fingerprints_file.exists():\n",
    "            try:\n",
    "                with open(self.fingerprints_file, 'r') as f:\n",
    "                    return set(json.load(f))\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Error loading fingerprints: {e}\")\n",
    "                return set()\n",
    "        return set()\n",
    "\n",
    "    def _load_bloom(self):\n",
    "        if self.bloom_file.exists():\n",
    "            try:\n",
    "                with open(self.bloom_file, \"rb\") as f:\n",
    "                    return pickle.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Error loading bloom filter: {e}\")\n",
    "\n",
    "        return BloomFilter(max_elements=2_000_000, error_rate=0.001)\n",
    "\n",
    "    def _normalize_text(self, text) -> str:\n",
    "        if not isinstance(text, str):\n",
    "            text = json.dumps(text, ensure_ascii=False)\n",
    "\n",
    "        text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "    def _create_fingerprint(self, card: Dict) -> str:\n",
    "        card_type = card.get(\"type\", \"basic\")\n",
    "\n",
    "        if card_type == \"basic\":\n",
    "            front = self._normalize_text(card.get(\"front\", \"\"))\n",
    "            back = self._normalize_text(card.get(\"back\", \"\"))[:300]\n",
    "            content = f\"{front}|{back}\"\n",
    "\n",
    "        elif card_type == \"cloze\":\n",
    "            cloze = card.get(\"cloze\", \"\")\n",
    "            clean = re.sub(r'\\{\\{c\\d+::(.*?)\\}\\}', r'\\1', cloze)\n",
    "            content = self._normalize_text(clean)\n",
    "\n",
    "        elif card_type == \"tradeoff\":\n",
    "            front = self._normalize_text(card.get(\"front\", \"\"))\n",
    "            approaches = [t.get(\"approach\", \"\") for t in card.get(\"tradeoffs\", [])]\n",
    "            content = f\"{front}|{' '.join(approaches)}\"\n",
    "\n",
    "        else:\n",
    "            content = \"\"\n",
    "\n",
    "        return hashlib.md5(content.encode()).hexdigest()\n",
    "\n",
    "    def is_duplicate(self, card: Dict) -> bool:\n",
    "        fingerprint = self._create_fingerprint(card)\n",
    "\n",
    "        ROUTING_METRICS[\"_bloom_total_checks\"] = \\\n",
    "            ROUTING_METRICS.get(\"_bloom_total_checks\", 0) + 1\n",
    "\n",
    "        if self.bloom and fingerprint not in self.bloom:\n",
    "            return False\n",
    "\n",
    "        with self.lock:\n",
    "            is_dup = fingerprint in self.fingerprints\n",
    "\n",
    "            if self.bloom and not is_dup:\n",
    "                ROUTING_METRICS[\"bloom_false_positive_suspected\"] = \\\n",
    "                    ROUTING_METRICS.get(\"bloom_false_positive_suspected\", 0) + 1\n",
    "\n",
    "            return is_dup\n",
    "\n",
    "    def add_fingerprint(self, fingerprint: str):\n",
    "        self.fingerprints.add(fingerprint)\n",
    "\n",
    "        if self.bloom:\n",
    "            self.bloom.add(fingerprint)\n",
    "\n",
    "        self._dirty = True\n",
    "        self._dirty_count += 1\n",
    "\n",
    "    def save_if_dirty(self, force: bool = False):\n",
    "        if not self._dirty:\n",
    "            return\n",
    "\n",
    "        if not force and self._dirty_count < CONFIG[\"FINGERPRINT_BATCH_SIZE\"]:\n",
    "            return\n",
    "\n",
    "        with self.lock:\n",
    "            try:\n",
    "                with open(self.fingerprints_file, 'w') as f:\n",
    "                    json.dump(list(self.fingerprints), f, indent=2)\n",
    "\n",
    "                if self.bloom:\n",
    "                    with open(self.bloom_file, \"wb\") as f:\n",
    "                        pickle.dump(self.bloom, f)\n",
    "\n",
    "                self._dirty = False\n",
    "                self._dirty_count = 0\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Error saving fingerprints: {e}\")\n",
    "\n",
    "class TerminalRejectionTracker:\n",
    "    \"\"\"\n",
    "    Track reels that are terminally rejected by logic.\n",
    "    Once a reel is marked terminal, it NEVER re-enters pipeline.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path: Path):\n",
    "        self.file_path = file_path\n",
    "        self.terminal_reels: Dict[str, Dict] = self._load()\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def _load(self) -> Dict[str, Dict]:\n",
    "        if self.file_path.exists():\n",
    "            try:\n",
    "                with open(self.file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    return data.get(\"terminal_reels\", {})\n",
    "            except Exception:\n",
    "                return {}\n",
    "        return {}\n",
    "\n",
    "    def mark_terminal(self, reel_id: str, reason: str = \"\", stage: str = \"stage1\", rejection_type: str = \"STRUCTURAL\"):\n",
    "        with self.lock:\n",
    "            self.terminal_reels[reel_id] = {\n",
    "                \"reason\": reason,\n",
    "                \"stage\": stage,\n",
    "                \"rejection_type\": rejection_type,\n",
    "                \"timestamp\": time.time()\n",
    "            }\n",
    "\n",
    "    def is_terminal(self, reel_id: str) -> bool:\n",
    "        with self.lock:\n",
    "            return reel_id in self.terminal_reels\n",
    "\n",
    "    def get_stats(self) -> Dict:\n",
    "        with self.lock:\n",
    "            reasons = defaultdict(int)\n",
    "            stages = defaultdict(int)\n",
    "            for entry in self.terminal_reels.values():\n",
    "                reasons[entry.get(\"reason\", \"unknown\")] += 1\n",
    "                stages[entry.get(\"stage\", \"unknown\")] += 1\n",
    "\n",
    "            return {\n",
    "                \"total\": len(self.terminal_reels),\n",
    "                \"by_reason\": dict(reasons),\n",
    "                \"by_stage\": dict(stages)\n",
    "            }\n",
    "\n",
    "    def save(self):\n",
    "        with self.lock:\n",
    "            try:\n",
    "                with open(self.file_path, 'w') as f:\n",
    "                    json.dump({\n",
    "                        \"terminal_reels\": self.terminal_reels,\n",
    "                        \"count\": len(self.terminal_reels)\n",
    "                    }, f, indent=2)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Failed to save terminal rejections: {e}\")\n",
    "\n",
    "class RejectionMemory:\n",
    "    \"\"\"\n",
    "    Consistent memory key across all operations\n",
    "    Key format: concept::category::topic_class\n",
    "    \"\"\"\n",
    "    def __init__(self, memory_file: Path):\n",
    "        self.memory_file = memory_file\n",
    "        self.memory = self._load()\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def _load(self) -> Dict:\n",
    "        if self.memory_file.exists():\n",
    "            try:\n",
    "                with open(self.memory_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except Exception:\n",
    "                return {}\n",
    "        return {}\n",
    "\n",
    "    def _make_key(self, concept: str, category: str = \"\", topic_class: str = \"\") -> str:\n",
    "        return f\"{concept}::{category}::{topic_class}\"\n",
    "\n",
    "    def _make_canonical_key(self, concept: str, category: str = \"\") -> str:\n",
    "        return f\"{concept}::{category or 'unknown'}\"\n",
    "\n",
    "    def record_rejection(self, concept: str, score: int, reason: str,\n",
    "                        category: str = \"\", topic_class: str = \"\"):\n",
    "        with self.lock:\n",
    "            key = self._make_key(concept, category, topic_class)\n",
    "\n",
    "            if key not in self.memory:\n",
    "                self.memory[key] = {\n",
    "                    \"concept\": concept,\n",
    "                    \"category\": category,\n",
    "                    \"topic_class\": topic_class,\n",
    "                    \"rejections\": [],\n",
    "                    \"successful_strategy\": None,\n",
    "                    \"first_seen_ts\": time.time(),\n",
    "                    \"first_success_ts\": None,\n",
    "                    \"attempts_until_success\": None\n",
    "                }\n",
    "\n",
    "            self.memory[key][\"rejections\"].append({\n",
    "                \"score\": score,\n",
    "                \"reason\": reason,\n",
    "                \"timestamp\": time.time()\n",
    "            })\n",
    "\n",
    "    def record_success(self, concept: str, strategy: str,\n",
    "                      category: str = \"\", topic_class: str = \"\",\n",
    "                      delta_score: int = 0):\n",
    "        with self.lock:\n",
    "            key = self._make_key(concept, category, topic_class)\n",
    "\n",
    "            if key in self.memory:\n",
    "                self.memory[key][\"successful_strategy\"] = {\n",
    "                    \"strategy\": strategy,\n",
    "                    \"delta_score\": delta_score,\n",
    "                    \"topic_class\": topic_class,\n",
    "                    \"timestamp\": time.time()\n",
    "                }\n",
    "\n",
    "                if self.memory[key].get(\"first_success_ts\") is None:\n",
    "                    self.memory[key][\"first_success_ts\"] = time.time()\n",
    "                    attempts = len(self.memory[key].get(\"rejections\", []))\n",
    "                    self.memory[key][\"attempts_until_success\"] = attempts\n",
    "\n",
    "                if \"success_by_topic_class\" not in self.memory[key]:\n",
    "                    self.memory[key][\"success_by_topic_class\"] = {}\n",
    "\n",
    "                tc = topic_class or \"unknown\"\n",
    "                if tc not in self.memory[key][\"success_by_topic_class\"]:\n",
    "                    self.memory[key][\"success_by_topic_class\"][tc] = 0\n",
    "                self.memory[key][\"success_by_topic_class\"][tc] += 1\n",
    "\n",
    "    def get_strategy(self, concept: str, category: str = \"\", topic_class: str = \"\") -> Optional[str]:\n",
    "        key = self._make_key(concept, category, topic_class)\n",
    "        entry = self.memory.get(key)\n",
    "        if entry and entry.get(\"successful_strategy\"):\n",
    "            success_matrix = entry.get(\"success_by_topic_class\", {})\n",
    "            if topic_class and success_matrix.get(topic_class, 0) > 0:\n",
    "                return entry.get(\"successful_strategy\")\n",
    "            elif not topic_class or not success_matrix:\n",
    "                return entry.get(\"successful_strategy\")\n",
    "\n",
    "        canonical_key = self._make_canonical_key(concept, category)\n",
    "        for stored_key, stored_entry in self.memory.items():\n",
    "            if stored_key.startswith(canonical_key + \"::\"):\n",
    "                if stored_entry.get(\"successful_strategy\"):\n",
    "                    return stored_entry.get(\"successful_strategy\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    def should_skip(self, concept: str, category: str = \"\", topic_class: str = \"\") -> bool:\n",
    "        key = self._make_key(concept, category, topic_class)\n",
    "        entry = self.memory.get(key)\n",
    "        if not entry:\n",
    "            return False\n",
    "\n",
    "        rejection_count = len(entry.get(\"rejections\", []))\n",
    "        has_success = entry.get(\"successful_strategy\") is not None\n",
    "\n",
    "        return rejection_count >= 3 and not has_success\n",
    "\n",
    "    def get_rejection_count(self, concept: str, category: str = \"\", topic_class: str = \"\") -> int:\n",
    "        key = self._make_key(concept, category, topic_class)\n",
    "        entry = self.memory.get(key)\n",
    "        if not entry:\n",
    "            return 0\n",
    "        return len(entry.get(\"rejections\", []))\n",
    "\n",
    "    def save(self, prune: bool = True):\n",
    "        with self.lock:\n",
    "            if prune:\n",
    "                TTL_DAYS = 90\n",
    "                now = time.time()\n",
    "                ttl_seconds = TTL_DAYS * 24 * 60 * 60\n",
    "\n",
    "                keys_to_remove = []\n",
    "                for key, entry in self.memory.items():\n",
    "                    first_seen = entry.get(\"first_seen_ts\", now)\n",
    "                    age_seconds = now - first_seen\n",
    "                    has_success = entry.get(\"successful_strategy\") is not None\n",
    "\n",
    "                    if age_seconds > ttl_seconds and not has_success:\n",
    "                        keys_to_remove.append(key)\n",
    "\n",
    "                for key in keys_to_remove:\n",
    "                    del self.memory[key]\n",
    "\n",
    "                if keys_to_remove:\n",
    "                    print(f\"      🧹 Pruned {len(keys_to_remove)} stale rejection memory entries (90+ days old, no success)\")\n",
    "\n",
    "            try:\n",
    "                with open(self.memory_file, 'w') as f:\n",
    "                    json.dump(self.memory, f, indent=2)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Failed to save rejection memory: {e}\")\n",
    "\n",
    "    def get_stats(self) -> Dict:\n",
    "        with self.lock:\n",
    "            total_concepts = len(self.memory)\n",
    "            total_rejections = sum(len(e.get(\"rejections\", [])) for e in self.memory.values())\n",
    "\n",
    "            strategies = defaultdict(int)\n",
    "            for entry in self.memory.values():\n",
    "                strategy = entry.get(\"successful_strategy\")\n",
    "                if strategy:\n",
    "                    if isinstance(strategy, dict):\n",
    "                        strategies[strategy.get(\"strategy\", \"unknown\")] += 1\n",
    "                    else:\n",
    "                        strategies[strategy] += 1\n",
    "\n",
    "            learning_velocities = []\n",
    "            for entry in self.memory.values():\n",
    "                if entry.get(\"attempts_until_success\") is not None:\n",
    "                    learning_velocities.append(entry[\"attempts_until_success\"])\n",
    "\n",
    "            avg_attempts = sum(learning_velocities) / len(learning_velocities) if learning_velocities else 0\n",
    "\n",
    "            return {\n",
    "                \"total_concepts\": total_concepts,\n",
    "                \"total_rejections\": total_rejections,\n",
    "                \"strategies\": dict(strategies),\n",
    "                \"learning_velocity\": {\n",
    "                    \"avg_attempts_until_success\": round(avg_attempts, 2),\n",
    "                    \"concepts_learned\": len(learning_velocities),\n",
    "                    \"concepts_still_learning\": total_concepts - len(learning_velocities)\n",
    "                }\n",
    "            }\n",
    "\n",
    "# Initialize instances (global)\n",
    "duplicate_detector = HybridDuplicateDetector(CARD_FINGERPRINTS_FILE, BLOOM_FILE)\n",
    "terminal_rejections = TerminalRejectionTracker(TERMINAL_REJECTIONS_FILE)\n",
    "\n",
    "# Initialize rejection memory if enabled\n",
    "rejection_memory = None\n",
    "if CONFIG[\"ENABLE_REJECTION_LEARNING\"]:\n",
    "    rejection_memory = RejectionMemory(REJECTION_MEMORY_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eaed9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: LLM & MODEL MANAGEMENT\n",
    "# ============================================================\n",
    "\n",
    "# Model configuration\n",
    "PIPELINE_MODELS = {\n",
    "    'extract': ModelConfig(\n",
    "        name='mistral:7b-instruct-v0.2',\n",
    "        temperature=0.1,\n",
    "        num_predict=2000\n",
    "    ),\n",
    "    'extract_retry': ModelConfig(\n",
    "        name='mistral:7b-instruct-v0.2',\n",
    "        temperature=0.15,\n",
    "        num_predict=1500\n",
    "    ),\n",
    "    'generate_basic': ModelConfig(\n",
    "        name='mistral:7b-instruct',\n",
    "        temperature=0.2,\n",
    "        num_predict=1500\n",
    "    ),\n",
    "    'generate_cloze': ModelConfig(\n",
    "        name='mistral:7b-instruct',\n",
    "        temperature=0.2,\n",
    "        num_predict=800\n",
    "    ),\n",
    "    'generate_tradeoff': ModelConfig(\n",
    "        name='qwen2.5:7b-instruct',\n",
    "        temperature=0.2,\n",
    "        num_predict=1200\n",
    "    ),\n",
    "    'validate': ModelConfig(\n",
    "        name='qwen2.5:7b-instruct',\n",
    "        temperature=0.05,\n",
    "        num_predict=500\n",
    "    ),\n",
    "}\n",
    "\n",
    "MODEL_FALLBACKS = {\n",
    "    'mistral:7b-instruct-v0.2': ['mistral:7b-instruct', 'mistral:latest'],\n",
    "    'llama3.1:8b-instruct-q8_0': [\n",
    "        'mistral:7b-instruct',\n",
    "        'qwen2.5:7b-instruct',\n",
    "        'llama3.1:8b-instruct-q4_0',\n",
    "        'llama3.1:latest'\n",
    "    ],\n",
    "    'qwen2.5:7b-instruct-q4_K_M': [\n",
    "        'qwen2.5:7b-instruct',\n",
    "        'mistral:7b-instruct',\n",
    "        'llama3.1:8b-instruct-q4_0'\n",
    "    ],\n",
    "    'qwen2.5:7b-instruct': [\n",
    "        'qwen2.5:latest',\n",
    "        'mistral:7b-instruct',\n",
    "        'phi3:mini'\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create session\n",
    "session = requests.Session()\n",
    "session.headers.update({\"Connection\": \"keep-alive\"})\n",
    "\n",
    "def gpu_available() -> bool:\n",
    "    try:\n",
    "        subprocess.check_output([\"nvidia-smi\"], stderr=subprocess.DEVNULL)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_gpu_memory() -> Optional[int]:\n",
    "    try:\n",
    "        output = subprocess.check_output(\n",
    "            [\"nvidia-smi\", \"--query-gpu=memory.total\", \"--format=csv,noheader,nounits\"],\n",
    "            stderr=subprocess.DEVNULL\n",
    "        ).decode()\n",
    "        return int(output.strip()) // 1024\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def model_supports_generate(model_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if model supports /api/generate endpoint.\n",
    "    Memoized for stability.\n",
    "    \"\"\"\n",
    "    with MODEL_CAPABILITY_LOCK:\n",
    "        if model_name in MODEL_CAPABILITY_CACHE:\n",
    "            return MODEL_CAPABILITY_CACHE[model_name]\n",
    "\n",
    "    model_lower = model_name.lower()\n",
    "\n",
    "    CHAT_ONLY_HINTS = [\"chat\", \"assistant\", \"instruct-chat\"]\n",
    "    if any(hint in model_lower for hint in CHAT_ONLY_HINTS):\n",
    "        result = False\n",
    "    elif \"embed\" in model_lower or \"embedding\" in model_lower:\n",
    "        result = False\n",
    "    else:\n",
    "        GENERATE_MODELS = [\n",
    "            \"mistral\", \"mixtral\", \"qwen\", \"phi\", \n",
    "            \"deepseek\", \"gemma\", \"codellama\", \"yi\"\n",
    "        ]\n",
    "        result = any(key in model_lower for key in GENERATE_MODELS)\n",
    "\n",
    "    with MODEL_CAPABILITY_LOCK:\n",
    "        MODEL_CAPABILITY_CACHE[model_name] = result\n",
    "\n",
    "    return result\n",
    "\n",
    "def check_ollama_health() -> bool:\n",
    "    try:\n",
    "        r = requests.get(f\"{CONFIG['OLLAMA_URL']}/api/tags\", timeout=5)\n",
    "        return r.status_code == 200\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_available_models() -> List[str]:\n",
    "    try:\n",
    "        r = requests.get(f\"{CONFIG['OLLAMA_URL']}/api/tags\", timeout=5)\n",
    "        r.raise_for_status()\n",
    "        return [m[\"name\"] for m in r.json().get(\"models\", [])]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def select_best_model(preferred: str, fallbacks: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Select best available model with generate capability check.\n",
    "    \"\"\"\n",
    "    available = set(get_available_models())\n",
    "\n",
    "    if preferred in available:\n",
    "        if model_supports_generate(preferred):\n",
    "            return preferred\n",
    "        else:\n",
    "            print(f\"   ⚠️  '{preferred}' exists but doesn't support generate endpoint\")\n",
    "\n",
    "    for fallback in fallbacks:\n",
    "        if fallback in available:\n",
    "            if model_supports_generate(fallback):\n",
    "                print(f\"   ⚠️  '{preferred}' not usable, using '{fallback}'\")\n",
    "                return fallback\n",
    "            else:\n",
    "                print(f\"   ⚠️  '{fallback}' doesn't support generate endpoint, skipping\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def validate_and_fix_models():\n",
    "    \"\"\"\n",
    "    Validate models and apply fallbacks.\n",
    "    \"\"\"\n",
    "    available = set(get_available_models())\n",
    "    missing = []\n",
    "\n",
    "    for stage, config in PIPELINE_MODELS.items():\n",
    "        if config.name not in available:\n",
    "            fallbacks = MODEL_FALLBACKS.get(config.name, [])\n",
    "            replacement = select_best_model(config.name, fallbacks)\n",
    "\n",
    "            if replacement:\n",
    "                PIPELINE_MODELS[stage].name = replacement\n",
    "            else:\n",
    "                missing.append((stage, config.name))\n",
    "        else:\n",
    "            if \"generate\" in stage and not model_supports_generate(config.name):\n",
    "                print(f\"   🚫 WARNING: {config.name} doesn't support generate endpoint!\")\n",
    "                print(f\"      Attempting to find generate-capable replacement...\")\n",
    "\n",
    "                fallbacks = MODEL_FALLBACKS.get(config.name, [])\n",
    "                replacement = select_best_model(config.name, fallbacks)\n",
    "\n",
    "                if replacement:\n",
    "                    PIPELINE_MODELS[stage].name = replacement\n",
    "                    print(f\"      ✅ Replaced with: {replacement}\")\n",
    "                else:\n",
    "                    missing.append((stage, config.name + \" (no generate support)\"))\n",
    "\n",
    "    return missing\n",
    "\n",
    "def warmup_models():\n",
    "    \"\"\"\n",
    "    Warm up models AND verify generate capability.\n",
    "    \"\"\"\n",
    "    print(\"\\n🔥 Warming up models...\")\n",
    "    unique_models = set(config.name for config in PIPELINE_MODELS.values())\n",
    "\n",
    "    failed_models = []\n",
    "    for model in unique_models:\n",
    "        try:\n",
    "            r = requests.post(\n",
    "                f\"{CONFIG['OLLAMA_URL']}/api/generate\",\n",
    "                json={\"model\": model, \"prompt\": \"test\", \"stream\": False, \"options\": {\"num_predict\": 1}},\n",
    "                timeout=30\n",
    "            )\n",
    "\n",
    "            if r.status_code == 400:\n",
    "                error_msg = r.json().get(\"error\", r.text)\n",
    "                if \"support\" in error_msg.lower() or \"not\" in error_msg.lower():\n",
    "                    print(f\"   🚫 {model} - Does not support /api/generate\")\n",
    "                    failed_models.append((model, \"no generate support\"))\n",
    "                    continue\n",
    "\n",
    "            r.raise_for_status()\n",
    "            print(f\"   ✅ {model}\")\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"   ⏱️  {model} - Slow to load (continuing anyway)\")\n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            if \"400\" in error_str or \"support\" in error_str.lower():\n",
    "                print(f\"   🚫 {model} - Likely no generate support\")\n",
    "                failed_models.append((model, str(e)))\n",
    "            else:\n",
    "                print(f\"   ⚠️  {model} - Error: {e}\")\n",
    "\n",
    "    if failed_models:\n",
    "        print(f\"\\n🚨 CRITICAL: {len(failed_models)} model(s) don't support /api/generate:\")\n",
    "\n",
    "        generate_stage_failures = []\n",
    "        for model, reason in failed_models:\n",
    "            print(f\"   ❌ {model}: {reason}\")\n",
    "            stages_using = [stage for stage, cfg in PIPELINE_MODELS.items() if cfg.name == model]\n",
    "            if stages_using:\n",
    "                print(f\"      Used in stages: {', '.join(stages_using)}\")\n",
    "\n",
    "                if any(\"generate\" in stage for stage in stages_using):\n",
    "                    generate_stage_failures.append((model, stages_using))\n",
    "\n",
    "        if generate_stage_failures:\n",
    "            print(f\"\\n❌ FATAL: Generation stages have non-functional models:\")\n",
    "            for model, stages in generate_stage_failures:\n",
    "                print(f\"   {model} → {', '.join(stages)}\")\n",
    "            print(f\"\\n💡 FIX: Run with different models or update PIPELINE_MODELS config\")\n",
    "            raise RuntimeError(\"Cannot proceed with broken generate-stage models\")\n",
    "\n",
    "        print()\n",
    "\n",
    "def llm(prompt: str, model_config: ModelConfig, timeout=600, max_retries=3) -> str:\n",
    "    \"\"\"\n",
    "    LLM interface with retry logic.\n",
    "    CRITICAL FIX #1: Removed invalid 'num_gpu' parameter\n",
    "    \"\"\"\n",
    "    prompt_len = len(prompt)\n",
    "    if prompt_len > 8000:\n",
    "        print(f\"         ⚠️  Very long prompt ({prompt_len} chars) - may cause context issues\")\n",
    "        if prompt_len > 15000:\n",
    "            print(f\"         🔴 Prompt exceeds 15K chars - truncating to prevent failure\")\n",
    "            prompt = prompt[:15000] + \"\\n\\nReturn ONLY valid JSON:\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": model_config.name,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False,\n",
    "                \"options\": {\n",
    "                    \"temperature\": model_config.temperature,\n",
    "                    \"top_p\": model_config.top_p,\n",
    "                    \"num_predict\": model_config.num_predict\n",
    "                },\n",
    "            }\n",
    "\n",
    "            r = session.post(\n",
    "                f\"{CONFIG['OLLAMA_URL']}/api/generate\",\n",
    "                json=payload,\n",
    "                timeout=timeout,\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "            return r.json()[\"response\"]\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 400:\n",
    "                error_detail = \"\"\n",
    "                try:\n",
    "                    error_detail = e.response.json()\n",
    "                except:\n",
    "                    error_detail = e.response.text\n",
    "\n",
    "                print(f\"         🔴 HTTP 400 Error from Ollama:\")\n",
    "                print(f\"            Model: {model_config.name}\")\n",
    "                print(f\"            Error: {error_detail}\")\n",
    "                print(f\"            Prompt length: {len(prompt)} chars\")\n",
    "\n",
    "                if \"context\" in str(error_detail).lower() or \"too long\" in str(error_detail).lower():\n",
    "                    print(f\"            💡 Likely cause: Prompt exceeds model context window\")\n",
    "\n",
    "                raise\n",
    "\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 404:\n",
    "                raise RuntimeError(\n",
    "                    f\"Model '{model_config.name}' not found. \"\n",
    "                    f\"Pull: ollama pull {model_config.name}\"\n",
    "                )\n",
    "            raise\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise RuntimeError(f\"Timeout after {max_retries} attempts\")\n",
    "            wait = 5 * (attempt + 1)\n",
    "            print(f\"      ⏳ Timeout, retrying in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"      🔄 Retry {attempt + 1}/{max_retries} in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "    raise RuntimeError(\"Max retries exceeded\")\n",
    "\n",
    "def extract_json(text: str, lenient: bool = False) -> Dict:\n",
    "    \"\"\"Extract JSON from LLM response\"\"\"\n",
    "    text = text.strip()\n",
    "\n",
    "    json_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "    if json_match:\n",
    "        text = json_match.group()\n",
    "\n",
    "    text = re.sub(r'[\\x00-\\x1F\\x7F]', '', text)\n",
    "\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        if lenient:\n",
    "            try:\n",
    "                text = re.sub(r',(\\s*[}\\]])', r'\\1', text)\n",
    "                text = re.sub(r'([{\\[,])\\s*,', r'\\1', text)\n",
    "                return json.loads(text)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c136a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: PROMPT MANAGEMENT & GENERATION\n",
    "# ============================================================\n",
    "\n",
    "# Progress tracker\n",
    "class ProgressTracker:\n",
    "    def __init__(self, progress_file: Path):\n",
    "        self.progress_file = progress_file\n",
    "        self.processed: Set[str] = self._load()\n",
    "        self.lock = Lock()\n",
    "        self._buffer: List[str] = []\n",
    "        self._buffer_size = 50\n",
    "\n",
    "    def _load(self) -> Set[str]:\n",
    "        if self.progress_file.exists():\n",
    "            try:\n",
    "                with open(self.progress_file, 'r') as f:\n",
    "                    return set(line.strip() for line in f if line.strip())\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Error loading progress: {e}\")\n",
    "                return set()\n",
    "        return set()\n",
    "\n",
    "    def mark_processed(self, reel_id: str):\n",
    "        with self.lock:\n",
    "            if reel_id not in self.processed:\n",
    "                self.processed.add(reel_id)\n",
    "                self._buffer.append(reel_id)\n",
    "\n",
    "                if len(self._buffer) >= self._buffer_size:\n",
    "                    self.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        if not self._buffer:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with open(self.progress_file, 'a') as f:\n",
    "                f.write('\\n'.join(self._buffer) + '\\n')\n",
    "            self._buffer.clear()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Error flushing progress: {e}\")\n",
    "\n",
    "progress_tracker = ProgressTracker(PROGRESS_FILE)\n",
    "\n",
    "# Caching\n",
    "CACHE_DIR = CONFIG[\"OUT_DIR\"] / \"cache\"\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def get_cached_result(reel_id: str, stage: str) -> Optional[Dict]:\n",
    "    cache_file = CACHE_DIR / f\"{reel_id}_{stage}.json\"\n",
    "    if cache_file.exists():\n",
    "        try:\n",
    "            with open(cache_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def save_cached_result(reel_id: str, stage: str, data: Dict):\n",
    "    cache_file = CACHE_DIR / f\"{reel_id}_{stage}.json\"\n",
    "    try:\n",
    "        with open(cache_file, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "    except Exception as e:\n",
    "        print(f\"      ⚠️  Cache save failed: {e}\")\n",
    "\n",
    "# Prompt version lifecycle management\n",
    "def load_prompt_version_stats():\n",
    "    \"\"\"Load prompt version statistics for lifecycle management\"\"\"\n",
    "    if PROMPT_VERSION_FILE.exists():\n",
    "        try:\n",
    "            with open(PROMPT_VERSION_FILE, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_prompt_version_stats(stats):\n",
    "    \"\"\"Save prompt version statistics\"\"\"\n",
    "    try:\n",
    "        with open(PROMPT_VERSION_FILE, 'w') as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "    except Exception as e:\n",
    "        print(f\"      ⚠️  Failed to save prompt version stats: {e}\")\n",
    "\n",
    "def record_prompt_version_result(version: str, success: bool, stage: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Track success rates by prompt version for auto-deprecation.\n",
    "    Mechanical failures don't count against prompt quality.\n",
    "    \"\"\"\n",
    "    with PROMPT_VERSION_LOCK:\n",
    "        if version not in PROMPT_VERSION_STATS:\n",
    "            PROMPT_VERSION_STATS[version] = {\n",
    "                \"attempts\": 0,\n",
    "                \"successes\": 0,\n",
    "                \"deprecated\": False,\n",
    "                \"success_rate\": 0.0,\n",
    "                \"last_failure_stage\": None,\n",
    "                \"mechanical_failures\": 0\n",
    "            }\n",
    "\n",
    "        stats = PROMPT_VERSION_STATS[version]\n",
    "\n",
    "        if stage == \"mechanical\":\n",
    "            stats[\"mechanical_failures\"] += 1\n",
    "            return\n",
    "\n",
    "        stats[\"attempts\"] += 1\n",
    "        if success:\n",
    "            stats[\"successes\"] += 1\n",
    "        else:\n",
    "            stats[\"last_failure_stage\"] = stage\n",
    "\n",
    "        stats[\"success_rate\"] = stats[\"successes\"] / stats[\"attempts\"] if stats[\"attempts\"] > 0 else 0.0\n",
    "\n",
    "        if stats[\"attempts\"] >= 8 and stats[\"success_rate\"] < 0.35 and not stats[\"deprecated\"]:\n",
    "            stats[\"deprecated\"] = True\n",
    "            print(f\"      🚫 Auto-deprecated prompt version '{version}' (success rate: {stats['success_rate']:.1%} after {stats['attempts']} attempts)\")\n",
    "\n",
    "        if stats[\"deprecated\"] and stats[\"attempts\"] % 50 == 0:\n",
    "            if stats[\"success_rate\"] >= 0.45:\n",
    "                stats[\"deprecated\"] = False\n",
    "                print(f\"      ♻️  Un-deprecated prompt version '{version}' (success rate recovered: {stats['success_rate']:.1%})\")\n",
    "\n",
    "        if stats[\"attempts\"] % 10 == 0:\n",
    "            save_prompt_version_stats(PROMPT_VERSION_STATS)\n",
    "\n",
    "def is_prompt_version_deprecated(version: str) -> bool:\n",
    "    \"\"\"Check if a prompt version has been deprecated\"\"\"\n",
    "    return PROMPT_VERSION_STATS.get(version, {}).get(\"deprecated\", False)\n",
    "\n",
    "# Confidence calibration\n",
    "def load_confidence_calibration():\n",
    "    \"\"\"Load confidence calibration data\"\"\"\n",
    "    if CONFIDENCE_CALIBRATION_FILE.exists():\n",
    "        try:\n",
    "            with open(CONFIDENCE_CALIBRATION_FILE, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return CONFIDENCE_CALIBRATION\n",
    "    return CONFIDENCE_CALIBRATION\n",
    "\n",
    "def save_confidence_calibration():\n",
    "    \"\"\"Save confidence calibration data\"\"\"\n",
    "    with CONFIDENCE_CALIBRATION_LOCK:\n",
    "        try:\n",
    "            with open(CONFIDENCE_CALIBRATION_FILE, 'w') as f:\n",
    "                json.dump(CONFIDENCE_CALIBRATION, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Failed to save confidence calibration: {e}\")\n",
    "\n",
    "# Load existing calibration data\n",
    "CONFIDENCE_CALIBRATION = load_confidence_calibration()\n",
    "\n",
    "def track_confidence_outcome(confidence: float, accepted: bool = False):\n",
    "    \"\"\"\n",
    "    Track confidence calibration\n",
    "    Call this when you have human feedback on whether a card was accepted.\n",
    "    \"\"\"\n",
    "    bucket = None\n",
    "    if 0.5 <= confidence < 0.6:\n",
    "        bucket = \"0.5-0.6\"\n",
    "    elif 0.6 <= confidence < 0.7:\n",
    "        bucket = \"0.6-0.7\"\n",
    "    elif 0.7 <= confidence < 0.8:\n",
    "        bucket = \"0.7-0.8\"\n",
    "    elif 0.8 <= confidence < 0.9:\n",
    "        bucket = \"0.8-0.9\"\n",
    "    elif 0.9 <= confidence <= 1.0:\n",
    "        bucket = \"0.9-1.0\"\n",
    "\n",
    "    if bucket:\n",
    "        with CONFIDENCE_CALIBRATION_LOCK:\n",
    "            CONFIDENCE_CALIBRATION[\"buckets\"][bucket][\"total\"] += 1\n",
    "            if accepted:\n",
    "                CONFIDENCE_CALIBRATION[\"buckets\"][bucket][\"accepted\"] += 1\n",
    "\n",
    "# Stage 0: Transcript normalization\n",
    "def normalize_transcript(transcript: str, caption: str) -> str:\n",
    "    \"\"\"\n",
    "    PHASE 2: Transform spoken Instagram Reel transcript into structured content.\n",
    "    Converts conversational/spoken content into declarative educational prose.\n",
    "    \"\"\"\n",
    "    if not transcript or len(transcript.strip()) < 50:\n",
    "        return transcript\n",
    "    \n",
    "    filler_count = transcript.lower().count(\"so \") + transcript.lower().count(\"well \") + \\\n",
    "                   transcript.lower().count(\"let's \") + transcript.lower().count(\"hello \") + \\\n",
    "                   transcript.lower().count(\" follow \") + transcript.lower().count(\" follow @\")\n",
    "    \n",
    "    if filler_count < 2 and len(transcript.split()) > 100:\n",
    "        return transcript\n",
    "    \n",
    "    prompt = f\"\"\"You are a technical content normalizer for educational flashcards. Transform spoken Instagram Reel transcripts into structured technical prose.\n",
    "\n",
    "INPUT TRANSCRIPT (spoken/conversational):\n",
    "{transcript}\n",
    "\n",
    "TOPIC/CAPTION:\n",
    "{caption}\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Convert speech → declarative statements\n",
    "2. Remove ALL non-technical content:\n",
    "   - Filler: \"so\", \"well\", \"hello\", \"let's see\", \"right?\", \"okay\"\n",
    "   - Self-reference: \"I have created\", \"I will show\", \"comment link\", \"DM for\"\n",
    "   - CTAs: \"go ahead\", \"link in bio\", \"check out\", \"share with your friends\"\n",
    "3. Extract ONLY what was explicitly said or clearly implied\n",
    "4. Preserve: ALL technical terms, code examples, specific numbers/metrics\n",
    "5. Format as neutral technical explanation\n",
    "\n",
    "OUTPUT FORMAT (JSON):\n",
    "{{\n",
    "  \"normalized_content\": \"Technical explanation in declarative prose\",\n",
    "  \"key_concepts\": [\"term1\", \"term2\"],\n",
    "  \"has_code_example\": true/false,\n",
    "  \"content_type\": \"explanation|warning|comparison|definition\"\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON:\"\"\"\n",
    "\n",
    "    try:\n",
    "        raw = llm(prompt, PIPELINE_MODELS['extract'])\n",
    "        result = extract_json(raw, lenient=True)\n",
    "        \n",
    "        normalized = result.get(\"normalized_content\", \"\").strip()\n",
    "        content_type = result.get(\"content_type\", \"explanation\")\n",
    "        \n",
    "        if not normalized or len(normalized) < 50:\n",
    "            print(f\"      ⏭️  Normalization skipped: no technical content extracted\")\n",
    "            return transcript\n",
    "        \n",
    "        original_words = len(transcript.split())\n",
    "        normalized_words = len(normalized.split())\n",
    "        ratio = normalized_words / original_words if original_words > 0 else 0\n",
    "        \n",
    "        if ratio < 0.5:\n",
    "            print(f\"      ⚠️  Normalization suspicious: {ratio:.1%} of original length\")\n",
    "            return transcript\n",
    "        \n",
    "        if ratio > 2.0:\n",
    "            print(f\"      ⚠️  Normalization rejected: {ratio:.1%} of original (hallucination risk)\")\n",
    "            return transcript\n",
    "        \n",
    "        if normalized.lower().strip() == transcript.lower().strip():\n",
    "            return transcript\n",
    "        \n",
    "        print(f\"      ✨ Normalized: {original_words}w → {normalized_words}w ({ratio:.0%}, {content_type})\")\n",
    "        return normalized\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      ⚠️  Normalization error: {e}\")\n",
    "        return transcript\n",
    "\n",
    "# Stage 1: Atom extraction prompts\n",
    "def stage1_prompt_a_strict(caption: str, transcript: str) -> str:\n",
    "    \"\"\"PROMPT A — STRICT/ADVANCED\"\"\"\n",
    "    return f\"\"\"Extract COMPREHENSIVE technical atoms for ADVANCED topics.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. IGNORE: Company names, celebrity names, dates, marketing language\n",
    "2. Focus on CONCRETE mechanisms and SPECIFIC implementations\n",
    "3. Provide DEEP technical details with internal behavior\n",
    "4. DO NOT introduce unrelated or orthogonal concepts\n",
    "5. MUST extract AT LEAST 4 technical points and 2 solutions\n",
    "\n",
    "PRIMARY CONCEPT:\n",
    "- Main concept name (precise technical term)\n",
    "- Definition (one clear sentence with technical precision)\n",
    "- Detailed mechanisms (4-6 points explaining HOW it works internally)\n",
    "- Concrete solutions with SPECIFIC implementations\n",
    "- System impact (quantifiable: latency, throughput, availability)\n",
    "\n",
    "RELATED CONCEPTS (1-3 directly connected topics):\n",
    "Only if they are direct prerequisites, consequences, or internal mechanisms.\n",
    "\n",
    "OUTPUT SCHEMA:\n",
    "{{\n",
    "  \"valid\": true|false,\n",
    "  \"reject_reason\": \"string if invalid, empty otherwise\",\n",
    "  \"concept\": \"Technical term\",\n",
    "  \"category\": \"java_spring|azure|microservices|system_design|dsa|java_programming|java_developer|algorithms\",\n",
    "  \"definition\": \"Precise one-sentence definition\",\n",
    "  \"technical_points\": [\"...\", \"...\", \"...\", \"...\"],\n",
    "  \"solutions\": [\"...\", \"...\"],\n",
    "  \"impact\": [\"...\", \"...\", \"...\"],\n",
    "  \"has_tradeoffs\": true|false,\n",
    "  \"related_concepts\": [\n",
    "    {{\n",
    "      \"name\": \"Related concept\",\n",
    "      \"why_relevant\": \"Connection reason\",\n",
    "      \"key_points\": [\"...\", \"...\", \"...\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Caption: {caption}\n",
    "Transcript: {transcript}\n",
    "\n",
    "Return ONLY valid JSON:\"\"\"\n",
    "\n",
    "def stage1_prompt_b_foundation(caption: str, transcript: str) -> str:\n",
    "    \"\"\"PROMPT B — FOUNDATION-AWARE\"\"\"\n",
    "    return f\"\"\"Extract technical atoms for FOUNDATIONAL Java interview concepts.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. IGNORE: Company names, celebrity names, dates, marketing language\n",
    "2. Focus on INTERNAL BEHAVIOR appropriate to concept level\n",
    "3. Provide technical details that explain WHY and HOW\n",
    "4. DO NOT invent JVM internals unless mentioned\n",
    "5. REJECT: Generic advice, motivational content, \"just do X\" statements\n",
    "6. REQUIRE: At least one of: decision, tradeoff, failure mode, or counterexample\n",
    "7. MUST extract AT LEAST 3 technical points and 1 solution\n",
    "\n",
    "MANDATORY EXTRACTION REQUIREMENT:\n",
    "Extract AT LEAST ONE of the following:\n",
    "- A technical decision (when to use X vs Y)\n",
    "- A tradeoff (pros/cons of approach)\n",
    "- A failure mode (what goes wrong if...)\n",
    "- A counterexample (when this doesn't apply)\n",
    "\n",
    "If the content is purely motivational or generic advice, set valid=false with reason \"motivational_content\".\n",
    "\n",
    "PRIMARY CONCEPT:\n",
    "- Main concept name (precise technical term)\n",
    "- Definition (one clear sentence)\n",
    "- Internal mechanisms (3-5 points on HOW it works)\n",
    "- Concrete examples with code snippets or specific scenarios\n",
    "- Practical impact (thread safety, memory, performance)\n",
    "\n",
    "RELATED CONCEPTS (2-3 pedagogically connected topics):\n",
    "Only if commonly taught together or frequently co-asked.\n",
    "\n",
    "OUTPUT SCHEMA:\n",
    "{{\n",
    "  \"valid\": true|false,\n",
    "  \"reject_reason\": \"string if invalid, empty otherwise\",\n",
    "  \"concept\": \"Technical term\",\n",
    "  \"category\": \"java_spring|azure|microservices|system_design|dsa|java_programming|java_developer|algorithms\",\n",
    "  \"definition\": \"Clear one-sentence definition\",\n",
    "  \"technical_points\": [\"...\", \"...\", \"...\"],\n",
    "  \"solutions\": [\"...\", \"...\"],\n",
    "  \"impact\": [\"...\", \"...\"],\n",
    "  \"has_tradeoffs\": true|false,\n",
    "  \"related_concepts\": [\n",
    "    {{\n",
    "      \"name\": \"Pedagogically connected concept\",\n",
    "      \"relation_type\": \"pedagogical\",\n",
    "      \"why_relevant\": \"How they're taught together\",\n",
    "      \"key_points\": [\"...\", \"...\", \"...\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Caption: {caption}\n",
    "Transcript: {transcript}\n",
    "\n",
    "Return ONLY valid JSON:\"\"\"\n",
    "\n",
    "def stage1_prompt_c_dsa(caption: str, transcript: str) -> str:\n",
    "    \"\"\"PROMPT C — DSA-FOCUSED\"\"\"\n",
    "    return f\"\"\"Extract technical atoms for ALGORITHM/DATA STRUCTURE concepts.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. IGNORE: Company names, celebrity names, dates\n",
    "2. Focus on STEP-BY-STEP logic and COMPLEXITY analysis\n",
    "3. Provide concrete examples and edge cases\n",
    "4. Include time/space complexity\n",
    "5. MUST extract AT LEAST 4 technical points including complexity\n",
    "\n",
    "PRIMARY CONCEPT:\n",
    "- Algorithm/data structure name\n",
    "- Definition (one clear sentence)\n",
    "- Step-by-step logic (4-6 steps)\n",
    "- Time and space complexity (MUST include Big O notation)\n",
    "- Edge cases and optimizations\n",
    "\n",
    "OUTPUT SCHEMA:\n",
    "{{\n",
    "  \"valid\": true|false,\n",
    "  \"reject_reason\": \"string if invalid, empty otherwise\",\n",
    "  \"concept\": \"Algorithm/Data structure name\",\n",
    "  \"category\": \"dsa|algorithms\",\n",
    "  \"definition\": \"Clear definition\",\n",
    "  \"technical_points\": [\"Step 1...\", \"Step 2...\", \"Complexity: O(...)\"],\n",
    "  \"solutions\": [\"Code example\", \"Optimization\"],\n",
    "  \"impact\": [\"Performance characteristics\"],\n",
    "  \"has_tradeoffs\": true|false,\n",
    "  \"related_concepts\": [\n",
    "    {{\n",
    "      \"name\": \"Related algorithm/structure\",\n",
    "      \"why_relevant\": \"Comparison or prerequisite\",\n",
    "      \"key_points\": [\"...\", \"...\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Caption: {caption}\n",
    "Transcript: {transcript}\n",
    "\n",
    "Return ONLY valid JSON:\"\"\"\n",
    "\n",
    "def create_enrichment_prompt(atoms: Dict, strategy: Optional[str] = None) -> str:\n",
    "    \"\"\"Create enrichment prompt based on learned strategy\"\"\"\n",
    "    base_prompt = f\"\"\"RE-EXTRACT with MORE TECHNICAL DEPTH.\n",
    "\n",
    "Previous extraction was too shallow. Provide:\n",
    "1. Deeper technical mechanisms\n",
    "2. More concrete examples\n",
    "3. Specific edge cases\n",
    "4. Implementation details\n",
    "5. MUST extract at least 4 technical points and 2 solutions\n",
    "\n",
    "Previous atoms:\n",
    "{json.dumps(atoms, indent=2)}\n",
    "\n",
    "Return enhanced JSON with same schema.\"\"\"\n",
    "\n",
    "    if strategy:\n",
    "        base_prompt += f\"\\n\\nUse strategy: {strategy}\"\n",
    "\n",
    "    return base_prompt\n",
    "\n",
    "# Prompt routing\n",
    "def select_prompt_strategy(caption: str, transcript: str, category: str,\n",
    "                          learned_override: Optional[str] = None) -> Tuple[PromptStrategy, str]:\n",
    "    \"\"\"\n",
    "    Select appropriate prompt based on content signals.\n",
    "    FIX #5: Block deprecated prompts during routing\n",
    "    \"\"\"\n",
    "    if CONFIG[\"ENABLE_PROMPT_ROUTING\"] and learned_override:\n",
    "        version_key = f\"stage1_{learned_override}_{CONFIG['CACHE_VERSION']}\"\n",
    "        if is_prompt_version_deprecated(version_key):\n",
    "            print(f\"      🚫 Learned strategy '{learned_override}' is deprecated - using heuristics\")\n",
    "            learned_override = None\n",
    "        else:\n",
    "            try:\n",
    "                strategy = PromptStrategy(learned_override)\n",
    "                ROUTING_METRICS[learned_override] += 1\n",
    "                ROUTING_COUNTS[learned_override] += 1\n",
    "                return strategy, f\"learned from past success on similar concept\"\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    text = f\"{caption} {transcript}\".lower()\n",
    "\n",
    "    # Content-based routing signals\n",
    "    tradeoff_patterns = [\n",
    "        \" vs \", \" vs.\", \"versus\", \"instead of\", \"rather than\",\n",
    "        \"trade-off\", \"tradeoff\", \"compare\", \"comparison\",\n",
    "        \"difference between\", \"advantage\", \"disadvantage\"\n",
    "    ]\n",
    "    if any(pattern in text for pattern in tradeoff_patterns):\n",
    "        ROUTING_METRICS[\"content_signal::tradeoff_detected\"] = \\\n",
    "            ROUTING_METRICS.get(\"content_signal::tradeoff_detected\", 0) + 1\n",
    "\n",
    "    decision_patterns = [\n",
    "        \"when to\", \"when should\", \"which to\", \"choose between\",\n",
    "        \"depends on\", \"if you\", \"use case\", \"scenario\"\n",
    "    ]\n",
    "    if any(pattern in text for pattern in decision_patterns):\n",
    "        ROUTING_METRICS[\"content_signal::decision_detected\"] = \\\n",
    "            ROUTING_METRICS.get(\"content_signal::decision_detected\", 0) + 1\n",
    "\n",
    "    # DSA/algorithms → DSA-focused\n",
    "    dsa_signals = [\n",
    "        \"algorithm\", \"complexity\", \"time complexity\", \"space complexity\",\n",
    "        \"binary search\", \"tree\", \"graph\", \"heap\", \"sort\", \"dynamic programming\",\n",
    "        \"big o\", \"o(n)\", \"o(log n)\", \"recursion\", \"backtracking\"\n",
    "    ]\n",
    "\n",
    "    if any(signal in text for signal in dsa_signals):\n",
    "        ROUTING_METRICS[\"C_DSA\"] += 1\n",
    "        ROUTING_COUNTS[\"C_DSA\"] += 1\n",
    "        return PromptStrategy.DSA_FOCUSED, \"DSA/algorithm signals detected\"\n",
    "\n",
    "    # Foundation topics + short transcript → foundation-aware\n",
    "    foundation_signals = [\n",
    "        \"string\", \"array\", \"list\", \"hashmap\", \"equals\", \"hashcode\",\n",
    "        \"inheritance\", \"polymorphism\", \"encapsulation\", \"interface\",\n",
    "        \"immutability\", \"immutable\", \"collection\", \"basics\", \"introduction\"\n",
    "    ]\n",
    "\n",
    "    transcript_length = len(transcript.split())\n",
    "\n",
    "    if transcript_length < 150 and any(signal in text for signal in foundation_signals):\n",
    "        ROUTING_METRICS[\"B_FOUNDATION\"] += 1\n",
    "        ROUTING_COUNTS[\"B_FOUNDATION\"] += 1\n",
    "        return PromptStrategy.FOUNDATION_AWARE, \"foundation topic with short transcript\"\n",
    "\n",
    "    # Advanced/system design → strict\n",
    "    advanced_signals = [\n",
    "        \"distributed\", \"microservice\", \"scalability\", \"consistency\",\n",
    "        \"saga\", \"cdc\", \"event sourcing\", \"kafka\", \"redis cluster\",\n",
    "        \"kubernetes\", \"docker\", \"load balancer\", \"api gateway\",\n",
    "        \"circuit breaker\", \"service mesh\", \"eventual consistency\"\n",
    "    ]\n",
    "\n",
    "    if any(signal in text for signal in advanced_signals):\n",
    "        ROUTING_METRICS[\"A_STRICT\"] += 1\n",
    "        ROUTING_COUNTS[\"A_STRICT\"] += 1\n",
    "        return PromptStrategy.STRICT_ADVANCED, \"advanced/system design signals\"\n",
    "\n",
    "    # Technical frameworks → foundation-aware\n",
    "    technical_signals = [\n",
    "        \"spring\", \"@autowired\", \"@transactional\", \"jpa\", \"hibernate\",\n",
    "        \"azure\", \"aks\", \"service bus\", \"cosmos db\"\n",
    "    ]\n",
    "\n",
    "    if any(signal in text for signal in technical_signals):\n",
    "        ROUTING_METRICS[\"B_FOUNDATION\"] += 1\n",
    "        ROUTING_COUNTS[\"B_FOUNDATION\"] += 1\n",
    "        return PromptStrategy.FOUNDATION_AWARE, \"technical framework signals\"\n",
    "\n",
    "    # Default to foundation-aware\n",
    "    ROUTING_METRICS[\"B_FOUNDATION\"] += 1\n",
    "    ROUTING_COUNTS[\"B_FOUNDATION\"] += 1\n",
    "    fallback_version = f\"stage1_{PromptStrategy.FOUNDATION_AWARE.value}_{CONFIG['CACHE_VERSION']}\"\n",
    "    if is_prompt_version_deprecated(fallback_version):\n",
    "        return PromptStrategy.FOUNDATION_AWARE, \"forced fallback (all others deprecated)\"\n",
    "\n",
    "    return PromptStrategy.FOUNDATION_AWARE, \"default (safest for mixed content)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e27ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: MAIN PIPELINE & ORCHESTRATION\n",
    "# ============================================================\n",
    "\n",
    "def compact_atoms_for_generation(atoms: Dict, max_chars: int = 2000) -> Dict:\n",
    "    \"\"\"\n",
    "    Compact atoms before Stage-2 to prevent context overflow\n",
    "    \"\"\"\n",
    "    compacted = {\n",
    "        \"concept\": atoms.get(\"concept\", \"\")[:200],\n",
    "        \"category\": atoms.get(\"category\", \"\"),\n",
    "        \"definition\": atoms.get(\"definition\", \"\")[:300],\n",
    "        \"technical_points\": atoms.get(\"technical_points\", [])[:4],\n",
    "        \"solutions\": atoms.get(\"solutions\", [])[:2],\n",
    "        \"impact\": atoms.get(\"impact\", [])[:2],\n",
    "        \"has_tradeoffs\": atoms.get(\"has_tradeoffs\", False),\n",
    "        \"related_concepts\": [\n",
    "            {\n",
    "                \"name\": rc.get(\"name\", \"\")[:100],\n",
    "                \"why_relevant\": rc.get(\"why_relevant\", \"\")[:150],\n",
    "                \"key_points\": rc.get(\"key_points\", [])[:2]\n",
    "            }\n",
    "            for rc in atoms.get(\"related_concepts\", [])[:2]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    compacted_str = json.dumps(compacted)\n",
    "    if len(compacted_str) > max_chars:\n",
    "        compacted[\"technical_points\"] = compacted[\"technical_points\"][:2]\n",
    "        compacted[\"related_concepts\"] = compacted[\"related_concepts\"][:1]\n",
    "        compacted_str = json.dumps(compacted)\n",
    "\n",
    "        if len(compacted_str) > max_chars:\n",
    "            compacted[\"related_concepts\"] = []\n",
    "\n",
    "    return compacted\n",
    "\n",
    "def validate_cloze(card: Dict, topic_class: str) -> bool:\n",
    "    \"\"\"\n",
    "    Topic-aware cloze validation\n",
    "    Foundation: 2 clozes minimum, 60 chars minimum\n",
    "    Intermediate/Advanced: 3 clozes minimum, 90 chars minimum\n",
    "    \"\"\"\n",
    "    cloze = card.get(\"cloze\", \"\")\n",
    "    cloze_count = cloze.count(\"{{c\")\n",
    "\n",
    "    if topic_class == \"foundation\":\n",
    "        return cloze_count >= 2 and len(cloze) >= 60\n",
    "    else:\n",
    "        return cloze_count >= 3 and len(cloze) >= 90\n",
    "\n",
    "# Stage 2: Card generation prompts\n",
    "def stage2a_basic_prompt(atoms: Dict) -> str:\n",
    "    clean_atoms = compact_atoms_for_generation(atoms)\n",
    "\n",
    "    return f\"\"\"Generate 2-3 BASIC interview cards.\n",
    "\n",
    "Input:\n",
    "{json.dumps(clean_atoms, indent=2)}\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Generate 2–3 cards for the PRIMARY concept\n",
    "2. Each card must be interview-ready with clear front/back\n",
    "3. Use bullet points for clarity in back\n",
    "4. Include concrete examples or code snippets\n",
    "5. Focus on understanding, not just facts\n",
    "\n",
    "OUTPUT JSON:\n",
    "{{\n",
    "  \"cards\": [\n",
    "    {{\n",
    "      \"type\": \"basic\",\n",
    "      \"concept_source\": \"primary\",\n",
    "      \"front\": \"Clear question about {clean_atoms.get('concept', 'concept')}\",\n",
    "      \"back\": \"Detailed answer with bullet points and examples\",\n",
    "      \"tags\": [\"domain:{clean_atoms.get('category', 'java')}\", \"difficulty:medium\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON.\"\"\"\n",
    "\n",
    "def stage2b_cloze_prompt(atoms: Dict) -> str:\n",
    "    clean_atoms = compact_atoms_for_generation(atoms)\n",
    "\n",
    "    return f\"\"\"Generate 1-2 CLOZE deletion cards.\n",
    "\n",
    "Input:\n",
    "{json.dumps(clean_atoms, indent=2)}\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Each card MUST have at least 2-3 deletions (topic-aware)\n",
    "2. Prefer mechanisms, definitions, and key concepts for cloze\n",
    "3. Length 60–180 characters (topic-aware)\n",
    "4. Avoid filler text - focus on core technical content\n",
    "5. Make deletions meaningful (key terms, not obvious fillers)\n",
    "\n",
    "FORMAT:\n",
    "Use {{{{c1:: }}}}, {{{{c2:: }}}}, {{{{c3:: }}}} syntax\n",
    "\n",
    "OUTPUT JSON:\n",
    "{{\n",
    "  \"cards\": [\n",
    "    {{\n",
    "      \"type\": \"cloze\",\n",
    "      \"concept_source\": \"primary\",\n",
    "      \"cloze\": \"Text with {{{{c1::term}}}} and {{{{c2::another}}}} deletion...\",\n",
    "      \"tags\": [\"domain:{clean_atoms.get('category', 'java')}\", \"difficulty:medium\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON.\"\"\"\n",
    "\n",
    "def stage2c_tradeoff_prompt(atoms: Dict) -> str:\n",
    "    if not atoms.get(\"has_tradeoffs\"):\n",
    "        return \"\"\n",
    "\n",
    "    clean_atoms = compact_atoms_for_generation(atoms)\n",
    "\n",
    "    return f\"\"\"Generate ONE TRADEOFF card.\n",
    "\n",
    "Input:\n",
    "{json.dumps(clean_atoms, indent=2)}\n",
    "\n",
    "RULES:\n",
    "1. Compare exactly 2–3 approaches\n",
    "2. Each approach MUST have 2 PROS and 2 CONS\n",
    "3. Focus on engineering tradeoffs (performance, complexity, maintainability)\n",
    "4. If no explicit alternative exists, infer the most common real-world alternative\n",
    "\n",
    "OUTPUT JSON:\n",
    "{{\n",
    "  \"cards\": [\n",
    "    {{\n",
    "      \"type\": \"tradeoff\",\n",
    "      \"concept_source\": \"primary\",\n",
    "      \"front\": \"What are the trade-offs when implementing {clean_atoms.get('concept', 'this concept')}?\",\n",
    "      \"tradeoffs\": [\n",
    "        {{\n",
    "          \"approach\": \"Approach name\",\n",
    "          \"pros\": [\"Performance benefit...\", \"Simplicity...\"],\n",
    "          \"cons\": [\"Memory overhead...\", \"Complexity...\"]\n",
    "        }}\n",
    "      ],\n",
    "      \"tags\": [\"domain:{clean_atoms.get('category', 'java')}\", \"difficulty:senior\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON.\"\"\"\n",
    "\n",
    "def generate_basic_cards(atoms: Dict) -> List[Dict]:\n",
    "    try:\n",
    "        prompt = stage2a_basic_prompt(atoms)\n",
    "        raw = llm(prompt, PIPELINE_MODELS['generate_basic'])\n",
    "        output = extract_json(raw, lenient=True)\n",
    "\n",
    "        if not output or not output.get(\"cards\"):\n",
    "            return []\n",
    "\n",
    "        if isinstance(output, list):\n",
    "            return output\n",
    "        elif isinstance(output, dict):\n",
    "            return output.get(\"cards\", [])\n",
    "        else:\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"         ⚠️  Basic generation failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_cloze_cards(atoms: Dict) -> List[Dict]:\n",
    "    try:\n",
    "        topic_class = atoms.get(\"topic_class\", \"intermediate\")\n",
    "        tech_points = atoms.get(\"technical_points\", [])\n",
    "        definition = atoms.get(\"definition\", \"\")\n",
    "\n",
    "        has_suitable_content = False\n",
    "        if topic_class == \"foundation\":\n",
    "            combined_text = f\"{definition} {' '.join(tech_points)}\"\n",
    "            has_definition = len(definition.split()) >= 5\n",
    "            has_is_statement = \" is \" in combined_text.lower() or \" are \" in combined_text.lower()\n",
    "            has_cause_effect = any(word in combined_text.lower() for word in [\"because\", \"therefore\", \"causes\", \"leads to\", \"results in\"])\n",
    "            has_suitable_content = has_definition or has_is_statement or has_cause_effect\n",
    "        else:\n",
    "            has_suitable_content = len(tech_points) >= 2\n",
    "\n",
    "        if not has_suitable_content:\n",
    "            return []\n",
    "\n",
    "        prompt = stage2b_cloze_prompt(atoms)\n",
    "        raw = llm(prompt, PIPELINE_MODELS['generate_cloze'])\n",
    "        output = extract_json(raw, lenient=True)\n",
    "\n",
    "        if not output or not output.get(\"cards\"):\n",
    "            return []\n",
    "\n",
    "        cards = output.get(\"cards\", []) if isinstance(output, dict) else output\n",
    "\n",
    "        valid_cards = []\n",
    "        for card in cards:\n",
    "            if validate_cloze(card, topic_class):\n",
    "                valid_cards.append(card)\n",
    "\n",
    "        return valid_cards\n",
    "    except Exception as e:\n",
    "        print(f\"         ⚠️  Cloze generation failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_tradeoff_cards(atoms: Dict) -> List[Dict]:\n",
    "    if not atoms.get(\"has_tradeoffs\") or not CONFIG[\"ENABLE_TRADEOFFS\"]:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        prompt = stage2c_tradeoff_prompt(atoms)\n",
    "        raw = llm(prompt, PIPELINE_MODELS['generate_tradeoff'])\n",
    "        output = extract_json(raw, lenient=True)\n",
    "\n",
    "        if not output or not output.get(\"cards\"):\n",
    "            return []\n",
    "\n",
    "        cards = output.get(\"cards\", []) if isinstance(output, dict) else output\n",
    "\n",
    "        valid_cards = []\n",
    "        for card in cards:\n",
    "            tradeoffs = card.get(\"tradeoffs\", [])\n",
    "            if len(tradeoffs) >= 2:\n",
    "                valid = all(\n",
    "                    len(t.get(\"pros\", [])) >= 2 and len(t.get(\"cons\", [])) >= 2\n",
    "                    for t in tradeoffs\n",
    "                )\n",
    "                if valid:\n",
    "                    valid_cards.append(card)\n",
    "\n",
    "        return valid_cards\n",
    "    except Exception as e:\n",
    "        print(f\"         ⚠️  Tradeoff generation failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_adjacent_card(atoms: Dict) -> Optional[Dict]:\n",
    "    try:\n",
    "        concept = atoms.get(\"concept\", \"\")\n",
    "        definition = atoms.get(\"definition\", \"\")\n",
    "        technical_points = atoms.get(\"technical_points\", [])\n",
    "\n",
    "        prompt = f\"\"\"Generate ONE adjacent basic card for a foundation concept.\n",
    "\n",
    "Original concept: {concept}\n",
    "Definition: {definition}\n",
    "Key points: {technical_points[:3]}\n",
    "\n",
    "Rules:\n",
    "1. Must directly relate to the SAME concept\n",
    "2. Focus on practical application, common mistake, or edge case\n",
    "3. Keep it simple and interview-ready\n",
    "4. No new concepts - only extensions of the original\n",
    "\n",
    "OUTPUT JSON:\n",
    "{{\n",
    "  \"type\": \"basic\",\n",
    "  \"concept_source\": \"adjacent\",\n",
    "  \"front\": \"Question about practical application of {concept}\",\n",
    "  \"back\": \"Answer with practical insight, common mistake, or edge case\",\n",
    "  \"tags\": [\"domain:foundation\", \"type:adjacent\"]\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON:\"\"\"\n",
    "\n",
    "        raw = llm(prompt, PIPELINE_MODELS['generate_basic'])\n",
    "        output = extract_json(raw, lenient=True)\n",
    "\n",
    "        if not output:\n",
    "            return None\n",
    "\n",
    "        if isinstance(output, dict) and \"type\" in output:\n",
    "            return output\n",
    "        elif isinstance(output, list) and len(output) > 0:\n",
    "            return output[0]\n",
    "        elif isinstance(output, dict) and \"cards\" in output:\n",
    "            cards = output[\"cards\"]\n",
    "            return cards[0] if cards else None\n",
    "\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"         ⚠️  Adjacent card generation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def determine_completion_state(card_count: int, has_tradeoffs: bool, tradeoff_count: int,\n",
    "                              duplicates_filtered: int = 0, topic_class: str = \"intermediate\") -> Tuple[CompletionState, str]:\n",
    "    \"\"\"\n",
    "    Returns (state, reason) for better observability.\n",
    "    \"\"\"\n",
    "    if card_count < CONFIG[\"MIN_CARDS_FOR_PARTIAL\"]:\n",
    "        if duplicates_filtered > 0:\n",
    "            return CompletionState.INCOMPLETE, \"duplicates_filtered\"\n",
    "        return CompletionState.INCOMPLETE, \"low_card_count\"\n",
    "\n",
    "    if card_count >= CONFIG[\"MIN_CARDS_FOR_FULL\"]:\n",
    "        if (topic_class != \"foundation\" and\n",
    "            has_tradeoffs and\n",
    "            tradeoff_count == 0 and\n",
    "            CONFIG[\"ENABLE_TRADEOFFS\"]):\n",
    "            return CompletionState.PARTIAL, \"missing_tradeoff\"\n",
    "        return CompletionState.FULL, \"complete\"\n",
    "\n",
    "    return CompletionState.PARTIAL, \"partial_cards\"\n",
    "\n",
    "def quality_score_fallback(card: Dict) -> int:\n",
    "    \"\"\"Enhanced quality scoring\"\"\"\n",
    "    score = 0\n",
    "    card_type = card.get(\"type\", \"basic\")\n",
    "\n",
    "    front = card.get(\"front\") or \"\"\n",
    "    back = card.get(\"back\") or \"\"\n",
    "    cloze = card.get(\"cloze\") or \"\"\n",
    "\n",
    "    full_text = f\"{front} {back} {cloze}\".strip()\n",
    "\n",
    "    if not full_text:\n",
    "        return 0\n",
    "\n",
    "    # Enhanced technical scoring\n",
    "    tech_count = 0\n",
    "    for kws in TECHNICAL_KEYWORDS.values():\n",
    "        for kw in kws:\n",
    "            if kw in full_text.lower():\n",
    "                tech_count += 1\n",
    "    \n",
    "    foundation_count = sum(1 for kw in FOUNDATION_ENHANCEMENT_KEYWORDS if kw in full_text.lower())\n",
    "    \n",
    "    score += min(tech_count * 6, 30)\n",
    "    score += min(foundation_count * 3, 15)\n",
    "\n",
    "    if card_type == \"basic\":\n",
    "        if len(back) >= 150:\n",
    "            score += 15\n",
    "        bullet_count = back.count(\"•\") + back.count(\"-\") + back.count(\"*\")\n",
    "        score += min(bullet_count * 3, 25)\n",
    "        if \"`\" in back or \"```\" in back:\n",
    "            score += 10\n",
    "\n",
    "    elif card_type == \"cloze\":\n",
    "        cloze_count = cloze.count(\"{{c\")\n",
    "        score += min(cloze_count * 8, 25)\n",
    "        if len(cloze) >= 120:\n",
    "            score += 15\n",
    "\n",
    "    if any(ind in front.lower() for ind in [\"what\", \"how\", \"why\", \"explain\", \"compare\", \"difference\"]):\n",
    "        score += 20\n",
    "    if len(front.split()) >= 5:\n",
    "        score += 10\n",
    "\n",
    "    return min(score, 100)\n",
    "\n",
    "def assign_priority(quality: int) -> str:\n",
    "    if quality >= 85:\n",
    "        return \"P0\"\n",
    "    elif quality >= 70:\n",
    "        return \"P1\"\n",
    "    else:\n",
    "        return \"P2\"\n",
    "\n",
    "def calculate_confidence(atoms: Dict, cards: List[Dict], quality_dims: QualityDimensions) -> float:\n",
    "    \"\"\"\n",
    "    Topic-aware confidence with floor for high-quality foundation cards\n",
    "    \"\"\"\n",
    "    topic_class = atoms.get(\"topic_class\", \"intermediate\")\n",
    "    expected_cards = TOPIC_CLASSES.get(topic_class, {}).get(\"expected_cards\", 3)\n",
    "\n",
    "    final_count = len(cards)\n",
    "    avg_quality = sum(quality_score_fallback(c) for c in cards) / max(final_count, 1)\n",
    "\n",
    "    # Base confidence calculation\n",
    "    card_factor = min(final_count / expected_cards, 1.0)\n",
    "    quality_factor = avg_quality / 100\n",
    "\n",
    "    confidence = (\n",
    "        card_factor * 0.4 +\n",
    "        quality_factor * 0.3 +\n",
    "        quality_dims.combined_score * 0.3\n",
    "    )\n",
    "\n",
    "    # CRITICAL FIX #7: Confidence MUST align with correctness\n",
    "    if quality_dims.correctness_score >= 0.9 and final_count >= 1:\n",
    "        confidence = max(confidence, 0.6)\n",
    "        print(f\"      🎯 High correctness ({quality_dims.correctness_score:.2f}) → confidence floor 0.6\")\n",
    "\n",
    "    # Adaptive foundation confidence boost\n",
    "    if topic_class == \"foundation\":\n",
    "        if quality_dims.correctness_score >= 0.95 and quality_dims.richness_score >= 0.75:\n",
    "            boost_factor = 1.35\n",
    "            confidence *= boost_factor\n",
    "            print(f\"      🚀 Foundation quality boost: {confidence:.2f} (correctness={quality_dims.correctness_score:.2f}, richness={quality_dims.richness_score:.2f})\")\n",
    "        elif quality_dims.correctness_score >= 0.9:\n",
    "            boost_factor = 1.2\n",
    "            confidence *= boost_factor\n",
    "            print(f\"      📈 Foundation moderate boost: {confidence:.2f}\")\n",
    "\n",
    "    # Confidence floor prevents penalizing high-quality foundational cards\n",
    "    if final_count >= 1 and avg_quality >= 70 and topic_class == \"foundation\":\n",
    "        confidence = max(confidence, 0.65)\n",
    "        print(f\"      🛡️  Foundation quality floor: {confidence:.2f}\")\n",
    "\n",
    "    # Incomplete completion state reduces confidence\n",
    "    completion_state_obj = atoms.get(\"_completion_state_obj\")\n",
    "    if completion_state_obj == CompletionState.INCOMPLETE:\n",
    "        penalty = 0.85 if topic_class == \"foundation\" else 0.6\n",
    "        confidence *= penalty\n",
    "        print(f\"      📉 Confidence reduced due to incomplete state ({topic_class}): {confidence:.2f}\")\n",
    "\n",
    "    # Topic-aware confidence floor\n",
    "    CONFIDENCE_FLOOR = {\n",
    "        \"foundation\": 0.45,\n",
    "        \"intermediate\": 0.50,\n",
    "        \"advanced\": 0.55\n",
    "    }\n",
    "    \n",
    "    floor = CONFIDENCE_FLOOR.get(topic_class, 0.50)\n",
    "    if confidence < floor:\n",
    "        print(f\"      🛡️  Applying confidence floor: {confidence:.2f} → {floor:.2f} ({topic_class})\")\n",
    "        confidence = floor\n",
    "\n",
    "    return min(confidence, 1.0)\n",
    "\n",
    "def extract_atoms_with_retry(reel: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract atoms with adaptive routing and enrichment.\n",
    "    All CRITICAL FIXES applied here.\n",
    "    \"\"\"\n",
    "    reel_id = str(reel.get(\"reel_id\", reel.get(\"id\", \"\")))\n",
    "    caption = str(reel.get(\"caption\", \"\"))\n",
    "    transcript = str(reel.get(\"transcript\", \"\"))\n",
    "    category = str(reel.get(\"category\", \"\"))\n",
    "\n",
    "    # PHASE 2: Apply transcript normalization\n",
    "    if CONFIG.get(\"ENABLE_TRANSCRIPT_NORMALIZATION\", True):\n",
    "        original_transcript = transcript\n",
    "        transcript = normalize_transcript(transcript, caption)\n",
    "        \n",
    "        if len(transcript) != len(original_transcript):\n",
    "            normalization_delta = len(transcript) - len(original_transcript)\n",
    "            ROUTING_METRICS[\"content_signal::transcript_normalized\"] += 1\n",
    "            ROUTING_METRICS[f\"content_signal::normalization_delta_avg\"] = \\\n",
    "                (ROUTING_METRICS.get(f\"content_signal::normalization_delta_avg\", 0) + normalization_delta) / 2\n",
    "\n",
    "    try:\n",
    "        # Check terminal rejections FIRST\n",
    "        if terminal_rejections.is_terminal(reel_id):\n",
    "            return {\n",
    "                \"reel_id\": reel_id,\n",
    "                \"status\": \"terminal_rejected\",\n",
    "                \"reason\": \"Previously rejected by logic - no retry allowed\"\n",
    "            }\n",
    "\n",
    "        # Check cache first\n",
    "        cached = get_cached_result(reel_id, \"stage1_atoms\")\n",
    "        if cached and cached.get(\"status\") == \"extracted\":\n",
    "            return cached\n",
    "\n",
    "        # Classify topic\n",
    "        topic_class = classify_topic(caption, category, transcript)\n",
    "\n",
    "        # Create normalized concept key upfront\n",
    "        normalized_concept = normalize_learning_key(caption)\n",
    "\n",
    "        # Get learned strategy from rejection memory\n",
    "        learned_override = None\n",
    "        if rejection_memory:\n",
    "            learned_override = rejection_memory.get_strategy(\n",
    "                concept=normalized_concept,\n",
    "                category=category,\n",
    "                topic_class=topic_class\n",
    "            )\n",
    "\n",
    "        # Select prompt strategy\n",
    "        strategy, routing_reason = select_prompt_strategy(\n",
    "            caption, transcript, category, learned_override\n",
    "        )\n",
    "\n",
    "        # Build prompt\n",
    "        if strategy == PromptStrategy.STRICT_ADVANCED:\n",
    "            prompt = stage1_prompt_a_strict(caption, transcript)\n",
    "        elif strategy == PromptStrategy.DSA_FOCUSED:\n",
    "            prompt = stage1_prompt_c_dsa(caption, transcript)\n",
    "        else:\n",
    "            prompt = stage1_prompt_b_foundation(caption, transcript)\n",
    "\n",
    "        # Call LLM\n",
    "        raw = llm(prompt, PIPELINE_MODELS['extract'])\n",
    "        atoms = extract_json(raw, lenient=True)\n",
    "\n",
    "        # Use caption as canonical learning_key, not LLM output\n",
    "        if AtomsSchema.validate(atoms):\n",
    "            atoms[\"learning_key\"] = normalized_concept\n",
    "\n",
    "            # Entropy-based augmentation for generic captions\n",
    "            word_count = len(normalized_concept.split())\n",
    "            concept_name = atoms.get(\"concept\", \"\")\n",
    "            if word_count < 4 and concept_name:\n",
    "                concept_normalized = re.sub(r'[^\\w\\s]', ' ', concept_name.lower()).strip()\n",
    "                atoms[\"learning_key\"] = f\"{normalized_concept}::{concept_normalized}\"\n",
    "                normalized_concept = atoms[\"learning_key\"]\n",
    "\n",
    "        # Validate\n",
    "        if not AtomsSchema.validate(atoms):\n",
    "            return {\n",
    "                \"reel_id\": reel_id,\n",
    "                \"status\": \"error\",\n",
    "                \"reason\": \"Invalid schema\"\n",
    "            }\n",
    "\n",
    "        if not atoms.get(\"valid\"):\n",
    "            reject_reason = atoms.get(\"reject_reason\", \"Unknown\")\n",
    "\n",
    "            terminal_rejections.mark_terminal(\n",
    "                reel_id,\n",
    "                reason=f\"handled_by_logic: {reject_reason}\",\n",
    "                stage=\"stage1\",\n",
    "                rejection_type=\"SEMANTIC_TERMINAL\"\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"reel_id\": reel_id,\n",
    "                \"status\": \"rejected\",\n",
    "                \"reason\": reject_reason,\n",
    "                \"handled_by_logic\": True\n",
    "            }\n",
    "\n",
    "        # Calculate technical score\n",
    "        tech_score_val = technical_score(\n",
    "            f\"{atoms.get('concept','')} {atoms.get('definition','')} \"\n",
    "            f\"{' '.join(atoms.get('technical_points', []))}\"\n",
    "        )\n",
    "\n",
    "        # Topic-aware thresholds\n",
    "        min_score = 4\n",
    "        if CONFIG.get(\"NORMALIZE_TECH_SCORES\"):\n",
    "            adjustment = TOPIC_CLASSES.get(topic_class, {}).get(\"threshold_adjustment\", 0)\n",
    "            min_score += adjustment\n",
    "\n",
    "        # Foundation topics: disable tradeoffs only if truly basic\n",
    "        if topic_class == \"foundation\":\n",
    "            has_comparison = any(word in transcript.lower() for word in [\"vs\", \"versus\", \"instead\", \"rather than\", \"compared\"])\n",
    "            if not has_comparison:\n",
    "                atoms[\"has_tradeoffs\"] = False\n",
    "            else:\n",
    "                atoms[\"has_tradeoffs\"] = (\n",
    "                    atoms.get(\"has_tradeoffs\", False) and\n",
    "                    len(atoms.get(\"related_concepts\", [])) >= 1\n",
    "                )\n",
    "\n",
    "        # Structural impossibility gate\n",
    "        char_length = len(transcript.strip())\n",
    "        if char_length < 80 and topic_class != \"foundation\":\n",
    "            print(f\"      🚫 Structural impossibility: transcript too short ({char_length} chars)\")\n",
    "            terminal_rejections.mark_terminal(\n",
    "                reel_id,\n",
    "                reason=\"insufficient_source_material\",\n",
    "                stage=\"stage1\",\n",
    "                rejection_type=\"STRUCTURAL\"\n",
    "            )\n",
    "            return {\n",
    "                \"reel_id\": reel_id,\n",
    "                \"status\": RejectionType.STRUCTURAL.value,\n",
    "                \"reason\": \"insufficient_source_material\",\n",
    "                \"skip_enrichment\": True\n",
    "            }\n",
    "\n",
    "        print(f\"      📊 Tech score: {tech_score_val} | class: {topic_class} | threshold: {min_score}\")\n",
    "\n",
    "        # Check if below threshold\n",
    "        if tech_score_val < min_score:\n",
    "            if topic_class == \"foundation\":\n",
    "                is_valuable = (\n",
    "                    len(atoms.get(\"related_concepts\", [])) > 0 or\n",
    "                    len(atoms.get(\"technical_points\", [])) >= 3 or\n",
    "                    atoms.get(\"definition\", \"\") != \"\"\n",
    "                )\n",
    "\n",
    "                if is_valuable:\n",
    "                    print(f\"      ✅ Foundation topic - pedagogically valuable (accepted despite score)\")\n",
    "                    atoms[\"low_density_but_valid\"] = True\n",
    "                else:\n",
    "                    print(f\"      ❌ Foundation topic - insufficient pedagogical value (rejected)\")\n",
    "            else:\n",
    "                print(f\"      ⚠️  Below depth threshold (rejected unless enriched)\")\n",
    "        else:\n",
    "            print(f\"      ✅ Passed depth threshold (accepted)\")\n",
    "\n",
    "        # Enrichment budget is per-concept, not per-reel\n",
    "        has_rejection_history = (\n",
    "            rejection_memory and\n",
    "            rejection_memory.get_rejection_count(normalized_concept, category, topic_class) > 0\n",
    "        )\n",
    "\n",
    "        # Predictive confidence check\n",
    "        would_have_low_confidence = (\n",
    "            len(atoms.get(\"technical_points\", [])) < 3 or\n",
    "            len(atoms.get(\"solutions\", [])) < 1 or\n",
    "            (topic_class != \"foundation\" and not atoms.get(\"has_tradeoffs\", False))\n",
    "        )\n",
    "\n",
    "        should_enrich = (\n",
    "            (tech_score_val < min_score or has_rejection_history or would_have_low_confidence) and\n",
    "            CONFIG[\"ENABLE_ENRICHMENT\"] and\n",
    "            not atoms.get(\"low_density_but_valid\", False)\n",
    "        )\n",
    "\n",
    "        if should_enrich:\n",
    "            concept = atoms.get(\"learning_key\")\n",
    "            enrichment_key = f\"{concept}::{category or 'unknown'}\"\n",
    "\n",
    "            # Topic-aware enrichment budget\n",
    "            max_enrichments = CONFIG[\"MAX_ENRICHMENTS_PER_CONCEPT\"].get(\n",
    "                topic_class,\n",
    "                CONFIG[\"MAX_ENRICHMENTS_PER_CONCEPT\"].get(\"intermediate\", 2)\n",
    "            )\n",
    "\n",
    "            # Check per-concept enrichment budget with temporal spacing\n",
    "            with ENRICHMENT_BUDGET_LOCK:\n",
    "                now = time.time()\n",
    "                last_enrichment = ENRICHMENT_TIMESTAMPS.get(enrichment_key, 0)\n",
    "                days_since_last = (now - last_enrichment) / (24 * 60 * 60)\n",
    "\n",
    "                if days_since_last > ENRICHMENT_BUDGET_RESET_DAYS:\n",
    "                    if ENRICHMENT_BUDGET[enrichment_key] > 0:\n",
    "                        print(f\"      🔄 Resetting enrichment budget ({days_since_last:.1f} days since last attempt)\")\n",
    "                    ENRICHMENT_BUDGET[enrichment_key] = 0\n",
    "\n",
    "                concept_enrichments = ENRICHMENT_BUDGET[enrichment_key]\n",
    "                already_enriched = concept_enrichments >= max_enrichments\n",
    "\n",
    "            if already_enriched:\n",
    "                print(f\"      ⏭️  Skipping enrichment - concept budget exhausted ({concept_enrichments}/{max_enrichments} for {topic_class})\")\n",
    "                print(f\"         Budget will reset in {max(0, ENRICHMENT_BUDGET_RESET_DAYS - days_since_last):.1f} days\")\n",
    "            else:\n",
    "                # Check rejection memory\n",
    "                if rejection_memory:\n",
    "                    if rejection_memory.should_skip(concept, category, topic_class):\n",
    "                        print(f\"      ⏭️  Skipping - too many rejections\")\n",
    "\n",
    "                        terminal_rejections.mark_terminal(\n",
    "                            reel_id,\n",
    "                            reason=\"repeatedly_failed_enrichment\",\n",
    "                            stage=\"stage1_enrichment\",\n",
    "                            rejection_type=\"SEMANTIC_TERMINAL\"\n",
    "                        )\n",
    "\n",
    "                        return {\n",
    "                            \"reel_id\": reel_id,\n",
    "                            \"status\": RejectionType.SEMANTIC.value,\n",
    "                            \"reason\": \"repeatedly_failed\"\n",
    "                        }\n",
    "\n",
    "                    strategy_hint = rejection_memory.get_strategy(concept, category, topic_class)\n",
    "                else:\n",
    "                    strategy_hint = None\n",
    "\n",
    "                enrichment_reason = (\n",
    "                    f\"low_score ({tech_score_val})\" if tech_score_val < min_score\n",
    "                    else \"predicted_low_confidence\" if would_have_low_confidence\n",
    "                    else \"rejection_history\"\n",
    "                )\n",
    "                print(f\"      🔄 Enriching (reason: {enrichment_reason}, strategy: {strategy_hint or 'default'})\")\n",
    "\n",
    "                # Increment using canonical key\n",
    "                with ENRICHMENT_BUDGET_LOCK:\n",
    "                    ENRICHMENT_BUDGET[enrichment_key] += 1\n",
    "                    ENRICHMENT_TIMESTAMPS[enrichment_key] = time.time()\n",
    "\n",
    "                ROUTING_METRICS[\"enriched\"] = ROUTING_METRICS.get(\"enriched\", 0) + 1\n",
    "\n",
    "            enrichment_start = time.time()\n",
    "\n",
    "            try:\n",
    "                enrichment_prompt = create_enrichment_prompt(atoms, strategy_hint)\n",
    "                enriched_raw = llm(enrichment_prompt, PIPELINE_MODELS['extract_retry'])\n",
    "                enriched_atoms = extract_json(enriched_raw, lenient=True)\n",
    "\n",
    "                if AtomsSchema.validate(enriched_atoms) and enriched_atoms.get(\"valid\"):\n",
    "                    new_score = technical_score(\n",
    "                        f\"{enriched_atoms.get('concept','')} {enriched_atoms.get('definition','')} \"\n",
    "                        f\"{' '.join(enriched_atoms.get('technical_points', []))}\"\n",
    "                    )\n",
    "\n",
    "                    print(f\"      ✨ Enriched score: {new_score} (was: {tech_score_val})\")\n",
    "\n",
    "                    score_improvement = new_score - tech_score_val\n",
    "                    if new_score >= min_score and score_improvement > 1:\n",
    "                        atoms = enriched_atoms\n",
    "                        tech_score_val = new_score\n",
    "                        atoms[\"was_enriched\"] = True\n",
    "                        atoms[\"_enrichment_attempts\"] = 1\n",
    "                        atoms[\"_elapsed_enrichment\"] = round(time.time() - enrichment_start, 2)\n",
    "                        atoms[\"_delta_score\"] = score_improvement\n",
    "                        print(f\"      ✅ Enrichment successful! (Δ={score_improvement})\")\n",
    "                    elif new_score >= min_score:\n",
    "                        print(f\"      ⚠️  Enrichment marginal (Δ={score_improvement}) - not learning from noise\")\n",
    "                    else:\n",
    "                        print(f\"      ⚠️  Still below threshold\")\n",
    "            except Exception as e:\n",
    "                print(f\"      ⚠️  Enrichment failed: {e}\")\n",
    "\n",
    "        # Final threshold check - SEMANTIC rejection\n",
    "        if tech_score_val < min_score and not atoms.get(\"low_density_but_valid\", False):\n",
    "            if rejection_memory:\n",
    "                concept_key = atoms.get(\"learning_key\", normalized_concept)\n",
    "                rejection_memory.record_rejection(\n",
    "                    concept_key,\n",
    "                    tech_score_val,\n",
    "                    f\"Low technical signal ({tech_score_val})\",\n",
    "                    category=category,\n",
    "                    topic_class=topic_class\n",
    "                )\n",
    "\n",
    "            return {\n",
    "                \"reel_id\": reel_id,\n",
    "                \"status\": RejectionType.SEMANTIC.value,\n",
    "                \"reason\": f\"Low technical signal ({tech_score_val})\"\n",
    "            }\n",
    "\n",
    "        # Success\n",
    "        atoms[\"reel_id\"] = reel_id\n",
    "        atoms[\"status\"] = \"extracted\"\n",
    "        atoms[\"tech_score\"] = tech_score_val\n",
    "        atoms[\"topic_class\"] = topic_class\n",
    "        atoms[\"prompt_strategy\"] = strategy.value\n",
    "\n",
    "        # Model-aware prompt versioning\n",
    "        model_name = PIPELINE_MODELS['extract'].name.replace(\":\", \"_\").replace(\".\", \"_\")\n",
    "        atoms[\"prompt_version\"] = f\"stage1_{strategy.value}_{model_name}_{CONFIG['CACHE_VERSION']}\"\n",
    "        atoms[\"routing_reason\"] = routing_reason\n",
    "\n",
    "        ROUTING_METRICS[f\"reason::{routing_reason}\"] = ROUTING_METRICS.get(f\"reason::{routing_reason}\", 0) + 1\n",
    "\n",
    "        save_cached_result(reel_id, \"stage1_atoms\", atoms)\n",
    "\n",
    "        return atoms\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"reel_id\": reel_id,\n",
    "            \"status\": \"error\",\n",
    "            \"reason\": str(e)\n",
    "        }\n",
    "\n",
    "def generate_cards_from_atoms(atoms: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Generate all card types from atoms with density-aware routing.\n",
    "    \"\"\"\n",
    "    reel_id = atoms.get(\"reel_id\", \"\")\n",
    "    prompt_recorded = False\n",
    "\n",
    "    try:\n",
    "        # Check cache\n",
    "        cached = get_cached_result(reel_id, \"stage2_cards\")\n",
    "        if cached and cached.get(\"status\") == \"success\":\n",
    "            return cached\n",
    "\n",
    "        print(f\"   🎴 Generating cards...\")\n",
    "        \n",
    "        # PHASE 3: Determine content density and route accordingly\n",
    "        if CONFIG.get(\"ENABLE_HYBRID_ROUTING\", True):\n",
    "            caption = atoms.get(\"caption\", \"\")\n",
    "            transcript = atoms.get(\"transcript\", \"\")\n",
    "            category = atoms.get(\"category\", \"\")\n",
    "            \n",
    "            content_density = classify_content_density(caption, transcript, category)\n",
    "            ROUTING_METRICS[f\"content_density::{content_density.value}\"] += 1\n",
    "            \n",
    "            if content_density == ContentDensity.DENSE:\n",
    "                print(f\"      📚 Dense content → Full card generation (basic + cloze + tradeoff)\")\n",
    "                basic_cards = generate_basic_cards(atoms)\n",
    "                cloze_cards = generate_cloze_cards(atoms)\n",
    "                tradeoff_cards = generate_tradeoff_cards(atoms)\n",
    "                all_cards = basic_cards + cloze_cards + tradeoff_cards\n",
    "                \n",
    "            elif content_density == ContentDensity.LIGHT:\n",
    "                print(f\"      📄 Light content → Reference cards only (basic)\")\n",
    "                basic_cards = generate_basic_cards(atoms)\n",
    "                all_cards = basic_cards\n",
    "                for card in all_cards:\n",
    "                    card[\"content_density\"] = \"light\"\n",
    "                    \n",
    "            else:\n",
    "                return {\n",
    "                    \"reel_id\": reel_id,\n",
    "                    \"status\": \"rejected\",\n",
    "                    \"reason\": \"Content too sparse for card generation\"\n",
    "                }\n",
    "        else:\n",
    "            print(f\"      📚 Hybrid routing disabled → Full card generation\")\n",
    "            basic_cards = generate_basic_cards(atoms)\n",
    "            cloze_cards = generate_cloze_cards(atoms)\n",
    "            tradeoff_cards = generate_tradeoff_cards(atoms)\n",
    "            all_cards = basic_cards + cloze_cards + tradeoff_cards\n",
    "            content_density = ContentDensity.DENSE\n",
    "\n",
    "        print(f\"      Basic: {len(basic_cards if 'basic_cards' in locals() else [])}, \"\n",
    "              f\"Cloze: {len(cloze_cards if 'cloze_cards' in locals() else [])}, \"\n",
    "              f\"Tradeoff: {len(tradeoff_cards if 'tradeoff_cards' in locals() else [])}\")\n",
    "\n",
    "        # Foundation Expansion (only for DENSE content)\n",
    "        topic_class = atoms.get(\"topic_class\", \"intermediate\")\n",
    "        if (content_density == ContentDensity.DENSE and\n",
    "            topic_class == \"foundation\" and\n",
    "            len(all_cards) <= 2 and\n",
    "            CONFIG.get(\"ENABLE_FOUNDATION_EXPANSION\", True)):\n",
    "\n",
    "            temp_dims = QualityDimensions.calculate(atoms, all_cards)\n",
    "\n",
    "            was_enriched = atoms.get(\"was_enriched\", False)\n",
    "            tech_score = atoms.get(\"tech_score\", 0)\n",
    "            min_score_for_expansion = 3\n",
    "\n",
    "            can_expand = (\n",
    "                temp_dims.correctness_score >= 0.9 and\n",
    "                temp_dims.richness_score < 0.7 and\n",
    "                not was_enriched and\n",
    "                tech_score >= min_score_for_expansion\n",
    "            )\n",
    "\n",
    "            if can_expand:\n",
    "                print(f\"      🌱 Attempting foundation expansion (correct but thin, no enrichment needed)...\")\n",
    "                adjacent_card = generate_adjacent_card(atoms)\n",
    "                if adjacent_card:\n",
    "                    all_cards.append(adjacent_card)\n",
    "                    print(f\"      ✅ Added adjacent card\")\n",
    "            elif was_enriched:\n",
    "                print(f\"      ⏭️  Skipping expansion - content was enriched (expansion is polish, not repair)\")\n",
    "            elif tech_score < min_score_for_expansion:\n",
    "                print(f\"      ⏭️  Skipping expansion - tech score too low ({tech_score} < {min_score_for_expansion})\")\n",
    "\n",
    "        if not all_cards:\n",
    "            return {\n",
    "                \"reel_id\": reel_id,\n",
    "                \"status\": \"rejected\",\n",
    "                \"reason\": \"No valid cards generated\"\n",
    "            }\n",
    "\n",
    "        # Filter duplicates but DEFER fingerprint registration\n",
    "        unique_cards = []\n",
    "        duplicates_found = 0\n",
    "        pending_fingerprints = []\n",
    "\n",
    "        for card in all_cards:\n",
    "            if not duplicate_detector.is_duplicate(card):\n",
    "                unique_cards.append(card)\n",
    "                fingerprint = duplicate_detector._create_fingerprint(card)\n",
    "                pending_fingerprints.append(fingerprint)\n",
    "            else:\n",
    "                duplicates_found += 1\n",
    "\n",
    "        if duplicates_found > 0:\n",
    "            print(f\"      🔄 Filtered {duplicates_found} duplicates\")\n",
    "\n",
    "        final_count = len(unique_cards)\n",
    "\n",
    "        if final_count == 0:\n",
    "            return {\n",
    "                \"reel_id\": reel_id,\n",
    "                \"status\": \"rejected\",\n",
    "                \"reason\": \"All cards were duplicates\"\n",
    "            }\n",
    "\n",
    "        # Quality scoring\n",
    "        quality_dims = QualityDimensions.calculate(atoms, unique_cards)\n",
    "\n",
    "        # Completion state with explicit reason\n",
    "        completion_state, completion_reason = determine_completion_state(\n",
    "            final_count,\n",
    "            atoms.get(\"has_tradeoffs\", False),\n",
    "            len(tradeoff_cards),\n",
    "            duplicates_found,\n",
    "            topic_class=atoms.get(\"topic_class\", \"intermediate\")\n",
    "        )\n",
    "\n",
    "        atoms[\"completion_state\"] = completion_state.value\n",
    "        atoms[\"completion_reason\"] = completion_reason\n",
    "        atoms[\"_completion_state_obj\"] = completion_state\n",
    "\n",
    "        # Confidence calculation\n",
    "        confidence = calculate_confidence(atoms, unique_cards, quality_dims)\n",
    "\n",
    "        # Assign priorities\n",
    "        for card in unique_cards:\n",
    "            card[\"quality\"] = quality_score_fallback(card)\n",
    "            card[\"priority\"] = assign_priority(card[\"quality\"])\n",
    "            assert reel_id, f\"CRITICAL: Card created without reel_id - {card.get('type', 'unknown')}\"\n",
    "            card[\"reel_id\"] = reel_id\n",
    "\n",
    "        # NOW register fingerprints after cards passed all quality gates\n",
    "        for fingerprint in pending_fingerprints:\n",
    "            duplicate_detector.add_fingerprint(fingerprint)\n",
    "\n",
    "        # Explicit approval logic\n",
    "        auto_approved = (\n",
    "            confidence >= 0.85 and\n",
    "            quality_dims.correctness_score >= 0.9\n",
    "        )\n",
    "\n",
    "        result = {\n",
    "            \"reel_id\": reel_id,\n",
    "            \"status\": \"success\",\n",
    "            \"cards\": unique_cards,\n",
    "            \"basic_count\": len(basic_cards),\n",
    "            \"cloze_count\": len(cloze_cards),\n",
    "            \"tradeoff_count\": len(tradeoff_cards),\n",
    "            \"duplicates_filtered\": duplicates_found,\n",
    "            \"final_count\": final_count,\n",
    "            \"confidence\": round(confidence, 2),\n",
    "            \"completion_state\": completion_state.value,\n",
    "            \"completion_reason\": completion_reason,\n",
    "            \"correctness_score\": quality_dims.correctness_score,\n",
    "            \"richness_score\": quality_dims.richness_score,\n",
    "            \"attempted_enrichment\": atoms.get(\"was_enriched\", False),\n",
    "            \"topic_class\": atoms.get(\"topic_class\", \"intermediate\"),\n",
    "            \"prompt_strategy\": atoms.get(\"prompt_strategy\", \"unknown\"),\n",
    "            \"prompt_version\": atoms.get(\"prompt_version\", \"unknown\"),\n",
    "            \"auto_approved\": auto_approved\n",
    "        }\n",
    "\n",
    "        save_cached_result(reel_id, \"stage2_cards\", result)\n",
    "\n",
    "        # Record prompt version success ONLY if cards meet minimum threshold\n",
    "        prompt_version = atoms.get(\"prompt_version\")\n",
    "        rejection_type = result.get(\"status\", \"\")\n",
    "\n",
    "        if prompt_version and rejection_type != RejectionType.MECHANICAL.value and not prompt_recorded:\n",
    "            if final_count >= CONFIG[\"MIN_CARDS_FOR_PARTIAL\"]:\n",
    "                record_prompt_version_result(prompt_version, True, stage=\"complete\")\n",
    "            else:\n",
    "                record_prompt_version_result(prompt_version, False, stage=\"generation\")\n",
    "            prompt_recorded = True\n",
    "\n",
    "        # Record success in rejection memory if enriched\n",
    "        if atoms.get(\"was_enriched\") and rejection_memory:\n",
    "            concept_key = atoms.get(\"learning_key\", atoms.get(\"concept\", \"\"))\n",
    "            delta_score = atoms.get(\"_delta_score\", 0)\n",
    "            rejection_memory.record_success(\n",
    "                concept_key,\n",
    "                atoms.get(\"prompt_strategy\", \"\"),\n",
    "                category=atoms.get(\"category\", \"\"),\n",
    "                topic_class=atoms.get(\"topic_class\", \"\"),\n",
    "                delta_score=delta_score\n",
    "            )\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        prompt_version = atoms.get(\"prompt_version\")\n",
    "        if prompt_version and not prompt_recorded:\n",
    "            record_prompt_version_result(prompt_version, False, stage=\"mechanical\")\n",
    "\n",
    "        return {\n",
    "            \"reel_id\": reel_id,\n",
    "            \"status\": \"error\",\n",
    "            \"reason\": str(e)\n",
    "        }\n",
    "\n",
    "def process_single_reel(reel: Dict) -> Dict:\n",
    "    \"\"\"Process one reel through the full pipeline\"\"\"\n",
    "    reel_id = str(reel.get(\"reel_id\", reel.get(\"id\", \"\")))\n",
    "\n",
    "    print(f\"\\n🎬 Reel {reel_id}: {reel.get('caption', '')[:50]}...\")\n",
    "\n",
    "    # Stage 1: Extract atoms\n",
    "    atoms = extract_atoms_with_retry(reel)\n",
    "\n",
    "    if atoms.get(\"status\") != \"extracted\":\n",
    "        print(f\"   ❌ {atoms.get('status')}: {atoms.get('reason')}\")\n",
    "        return atoms\n",
    "\n",
    "    print(f\"   ✅ Atoms extracted (score: {atoms.get('tech_score')}, class: {atoms.get('topic_class')})\")\n",
    "\n",
    "    # Stage 2: Generate cards\n",
    "    result = generate_cards_from_atoms(atoms)\n",
    "\n",
    "    if result.get(\"status\") == \"success\":\n",
    "        print(f\"   ✅ {result['final_count']} cards (confidence: {result['confidence']:.2f})\")\n",
    "    else:\n",
    "        print(f\"   ❌ {result.get('status')}: {result.get('reason')}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_batch(reels: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Process reels in parallel\"\"\"\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=CONFIG[\"MAX_WORKERS\"]) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_single_reel, reel): reel\n",
    "            for reel in reels\n",
    "        }\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "\n",
    "                # Periodic saves\n",
    "                duplicate_detector.save_if_dirty()\n",
    "                progress_tracker.flush()\n",
    "\n",
    "                # Mark as processed\n",
    "                if result.get(\"reel_id\"):\n",
    "                    progress_tracker.mark_processed(result[\"reel_id\"])\n",
    "\n",
    "            except Exception as e:\n",
    "                reel = futures[future]\n",
    "                reel_id = str(reel.get(\"reel_id\", reel.get(\"id\", \"\")))\n",
    "                print(f\"❌ Error processing reel {reel_id}: {e}\")\n",
    "                results.append({\n",
    "                    \"reel_id\": reel_id,\n",
    "                    \"status\": \"error\",\n",
    "                    \"reason\": str(e)\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "def is_card_worthy(reel: Dict) -> Tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    PHASE 1: Pre-filter to identify reels that are worth processing into Anki cards.\n",
    "    \"\"\"\n",
    "    transcript = reel.get(\"transcript\", \"\").strip()\n",
    "    caption = reel.get(\"caption\", \"\").strip()\n",
    "    category_confidence = reel.get(\"category_confidence\", 0)\n",
    "    \n",
    "    try:\n",
    "        category_confidence = int(category_confidence) if category_confidence else 0\n",
    "    except:\n",
    "        category_confidence = 0\n",
    "    \n",
    "    # Filter 1: Promotional CTA patterns\n",
    "    cta_patterns = [\n",
    "        \"comment link\",\n",
    "        \"link in bio\",\n",
    "        \"check out this document\",\n",
    "        \"get the link\",\n",
    "        \"dm for\",\n",
    "        \"link in comment\",\n",
    "        \"go ahead and check\",\n",
    "    ]\n",
    "    \n",
    "    combined_text = (transcript + \" \" + caption).lower()\n",
    "    \n",
    "    for pattern in cta_patterns:\n",
    "        if pattern in combined_text:\n",
    "            cta_count = combined_text.count(pattern)\n",
    "            word_count = len(combined_text.split())\n",
    "            if cta_count > 0 and word_count < 150:\n",
    "                return False, f\"promotional_cta: {pattern}\"\n",
    "    \n",
    "    # Filter 2: Length check\n",
    "    word_count = len(transcript.split())\n",
    "    if word_count < 80:\n",
    "        return False, f\"too_short: {word_count} words\"\n",
    "    \n",
    "    # Filter 3: Category confidence\n",
    "    if category_confidence < 70:\n",
    "        return False, f\"low_confidence: {category_confidence}\"\n",
    "    \n",
    "    # Filter 4: Pure motivational patterns\n",
    "    motivational_only = [\n",
    "        \"you must know\",\n",
    "        \"stop scrolling\",\n",
    "        \"trust me\",\n",
    "        \"no one is talking about\",\n",
    "    ]\n",
    "    \n",
    "    technical_indicators = [\n",
    "        \"code\",\n",
    "        \"method\",\n",
    "        \"function\",\n",
    "        \"class\",\n",
    "        \"variable\",\n",
    "        \"algorithm\",\n",
    "        \"data structure\",\n",
    "        \"exception\",\n",
    "        \"annotation\",\n",
    "        \"interface\",\n",
    "    ]\n",
    "    \n",
    "    has_motivational = any(pattern in combined_text for pattern in motivational_only)\n",
    "    has_technical = any(indicator in combined_text for indicator in technical_indicators)\n",
    "    \n",
    "    if has_motivational and not has_technical and word_count < 120:\n",
    "        return False, \"motivational_only\"\n",
    "    \n",
    "    return True, \"\"\n",
    "\n",
    "def diagnose_csv_file(csv_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Diagnose CSV file issues and provide actionable feedback.\n",
    "    \"\"\"\n",
    "    diagnosis = {\n",
    "        \"exists\": False,\n",
    "        \"readable\": False,\n",
    "        \"line_count\": 0,\n",
    "        \"issues\": [],\n",
    "        \"sample_lines\": []\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        csv_file = Path(csv_path)\n",
    "        diagnosis[\"exists\"] = csv_file.exists()\n",
    "\n",
    "        if not diagnosis[\"exists\"]:\n",
    "            diagnosis[\"issues\"].append(f\"File not found: {csv_path}\")\n",
    "            return diagnosis\n",
    "\n",
    "        with open(csv_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        diagnosis[\"readable\"] = True\n",
    "        diagnosis[\"line_count\"] = len(lines)\n",
    "\n",
    "        if len(lines) < 2:\n",
    "            diagnosis[\"issues\"].append(\"File has fewer than 2 lines (need header + data)\")\n",
    "            return diagnosis\n",
    "\n",
    "        header = lines[0].strip()\n",
    "        expected_fields = len(header.split(','))\n",
    "        diagnosis[\"expected_fields\"] = expected_fields\n",
    "        diagnosis[\"sample_lines\"].append(f\"Header: {header[:100]}...\")\n",
    "\n",
    "        bad_lines = []\n",
    "        for i, line in enumerate(lines[1:11], start=2):\n",
    "            field_count = len(line.split(','))\n",
    "            if field_count != expected_fields:\n",
    "                bad_lines.append((i, field_count, line.strip()[:80]))\n",
    "\n",
    "        if bad_lines:\n",
    "            diagnosis[\"issues\"].append(f\"Found {len(bad_lines)} lines with inconsistent field counts\")\n",
    "            for line_num, count, preview in bad_lines[:3]:\n",
    "                diagnosis[\"sample_lines\"].append(\n",
    "                    f\"Line {line_num}: has {count} fields (expected {expected_fields}): {preview}...\"\n",
    "                )\n",
    "\n",
    "    except Exception as e:\n",
    "        diagnosis[\"issues\"].append(f\"Error reading file: {e}\")\n",
    "\n",
    "    return diagnosis\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STARTING ANKI GENERATION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "\n",
    "    # Load CSV\n",
    "    if not Path(CONFIG[\"CSV_FILE\"]).exists():\n",
    "        print(f\"❌ CSV not found: {CONFIG['CSV_FILE']}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Robust CSV parsing with error handling\n",
    "    try:\n",
    "        df = pd.read_csv(CONFIG[\"CSV_FILE\"], sep=\"|\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"⚠️  CSV parsing error: {e}\")\n",
    "\n",
    "        print(f\"\\n🔍 Diagnosing CSV file...\")\n",
    "        diagnosis = diagnose_csv_file(CONFIG[\"CSV_FILE\"])\n",
    "\n",
    "        if diagnosis[\"issues\"]:\n",
    "            print(f\"   Found {len(diagnosis['issues'])} issue(s):\")\n",
    "            for issue in diagnosis[\"issues\"]:\n",
    "                print(f\"   ❌ {issue}\")\n",
    "\n",
    "        if diagnosis[\"sample_lines\"]:\n",
    "            print(f\"\\n   Sample lines:\")\n",
    "            for sample in diagnosis[\"sample_lines\"]:\n",
    "                print(f\"   {sample}\")\n",
    "\n",
    "        print(f\"\\n   Attempting robust parsing...\")\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                CONFIG[\"CSV_FILE\"],\n",
    "                sep=\"|\",\n",
    "                on_bad_lines='skip',\n",
    "                engine='python',\n",
    "                quoting=1,\n",
    "                encoding='utf-8'\n",
    "            )\n",
    "            print(f\"   ✅ Recovered with lenient parsing ({len(df)} rows)\")\n",
    "        except Exception as e2:\n",
    "            print(f\"   ❌ Lenient parsing also failed: {e2}\")\n",
    "            print(f\"\\n💡 SUGGESTION: Fix your CSV file:\")\n",
    "            print(f\"   1. Ensure all text fields with commas are properly quoted\")\n",
    "            print(f\"   2. Check that all rows have the same number of columns\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    print(f\"📄 Loaded {len(df)} reels from CSV\")\n",
    "\n",
    "    # Normalize NaN values to prevent float crashes\n",
    "    def normalize_reel(reel: dict) -> dict:\n",
    "        normalized = {}\n",
    "        for k, v in reel.items():\n",
    "            if isinstance(v, float):\n",
    "                import math\n",
    "                if math.isnan(v):\n",
    "                    normalized[k] = \"\"\n",
    "                else:\n",
    "                    normalized[k] = str(v)\n",
    "            else:\n",
    "                normalized[k] = v\n",
    "        return normalized\n",
    "\n",
    "    # Filter unprocessed\n",
    "    unprocessed = []\n",
    "    for _, row in df.iterrows():\n",
    "        reel_dict = normalize_reel(row.to_dict())\n",
    "        reel_id = str(reel_dict.get(\"reel_id\", \"\"))\n",
    "        if reel_id not in progress_tracker.processed:\n",
    "            unprocessed.append(reel_dict)\n",
    "\n",
    "    print(f\"♻️  {len(progress_tracker.processed)} already processed\")\n",
    "    print(f\"🆕 {len(unprocessed)} remaining\")\n",
    "    print()\n",
    "\n",
    "    if not unprocessed:\n",
    "        print(\"✅ All reels already processed!\")\n",
    "        return\n",
    "\n",
    "    # PHASE 1: Apply pre-filtering\n",
    "    if CONFIG.get(\"ENABLE_CONTENT_FILTERING\", True):\n",
    "        print(f\"🔍 Applying content quality filters...\")\n",
    "        filtered_reels = []\n",
    "        skip_stats = defaultdict(int)\n",
    "        \n",
    "        for reel in unprocessed:\n",
    "            is_worthy, skip_reason = is_card_worthy(reel)\n",
    "            if is_worthy:\n",
    "                filtered_reels.append(reel)\n",
    "            else:\n",
    "                skip_stats[skip_reason] += 1\n",
    "                reel_id = str(reel.get(\"reel_id\", reel.get(\"id\", \"\")))\n",
    "                if reel_id:\n",
    "                    progress_tracker.mark_processed(reel_id)\n",
    "        \n",
    "        print(f\"✅ {len(filtered_reels)} reels passed quality filters\")\n",
    "        print(f\"⏭️  {len(unprocessed) - len(filtered_reels)} reels skipped:\")\n",
    "        for reason, count in sorted(skip_stats.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"   - {reason}: {count}\")\n",
    "        print()\n",
    "        \n",
    "        if not filtered_reels:\n",
    "            print(\"⚠️  No reels passed quality filters!\")\n",
    "            return\n",
    "    else:\n",
    "        print(f\"⏭️  Content filtering disabled - processing all reels\")\n",
    "        filtered_reels = unprocessed\n",
    "\n",
    "    # Limit to MAX_REELS\n",
    "    to_process = filtered_reels[:CONFIG[\"MAX_REELS\"]]\n",
    "\n",
    "    if len(to_process) < len(unprocessed):\n",
    "        print(f\"⚠️  Processing first {CONFIG['MAX_REELS']} reels (use MAX_REELS config to adjust)\")\n",
    "\n",
    "    # Process in batches\n",
    "    all_results = []\n",
    "    batch_size = CONFIG[\"BATCH_SIZE\"]\n",
    "\n",
    "    for i in range(0, len(to_process), batch_size):\n",
    "        batch = to_process[i:i + batch_size]\n",
    "        print(f\"\\n📦 Batch {i // batch_size + 1}/{(len(to_process) - 1) // batch_size + 1}\")\n",
    "\n",
    "        batch_results = process_batch(batch)\n",
    "        all_results.extend(batch_results)\n",
    "\n",
    "    # Save final state\n",
    "    duplicate_detector.save_if_dirty(force=True)\n",
    "    progress_tracker.flush()\n",
    "    if rejection_memory:\n",
    "        rejection_memory.save()\n",
    "\n",
    "    # Save routing metrics\n",
    "    try:\n",
    "        with open(ROUTING_METRICS_FILE, 'w') as f:\n",
    "            json.dump(dict(ROUTING_METRICS), f, indent=2)\n",
    "        print(f\"\\n💾 Routing metrics saved to: {ROUTING_METRICS_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Failed to save routing metrics: {e}\")\n",
    "\n",
    "    # Generate output\n",
    "    successful = [r for r in all_results if r.get(\"status\") == \"success\"]\n",
    "\n",
    "    all_cards = []\n",
    "    for result in successful:\n",
    "        all_cards.extend(result.get(\"cards\", []))\n",
    "\n",
    "    output_file = CONFIG[\"OUT_DIR\"] / \"anki_cards.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(all_cards, f, indent=2)\n",
    "\n",
    "    # Needs review\n",
    "    needs_review = [r for r in successful if 0.65 <= r.get(\"confidence\", 0) < 0.85]\n",
    "    if needs_review:\n",
    "        review_file = CONFIG[\"OUT_DIR\"] / \"needs_review.json\"\n",
    "        with open(review_file, 'w') as f:\n",
    "            json.dump(needs_review, f, indent=2)\n",
    "\n",
    "    # Summary stats\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    total_cards = len(all_cards)\n",
    "    basic_cards = sum(1 for c in all_cards if c.get(\"type\") == \"basic\")\n",
    "    cloze_cards = sum(1 for c in all_cards if c.get(\"type\") == \"cloze\")\n",
    "    tradeoff_cards = sum(1 for c in all_cards if c.get(\"type\") == \"tradeoff\")\n",
    "\n",
    "    total_duplicates = sum(r.get(\"duplicates_filtered\", 0) for r in successful)\n",
    "\n",
    "    avg_quality = sum(c.get(\"quality\", 0) for c in all_cards) / max(len(all_cards), 1)\n",
    "    avg_confidence = sum(r.get(\"confidence\", 0) for r in successful) / max(len(successful), 1)\n",
    "\n",
    "    p0_cards = sum(1 for c in all_cards if c.get(\"priority\") == \"P0\")\n",
    "    p1_cards = sum(1 for c in all_cards if c.get(\"priority\") == \"P1\")\n",
    "    p2_cards = sum(1 for c in all_cards if c.get(\"priority\") == \"P2\")\n",
    "\n",
    "    high_confidence = [r for r in successful if r.get(\"confidence\", 0) >= 0.85]\n",
    "    low_confidence = [r for r in successful if r.get(\"confidence\", 0) < 0.65]\n",
    "\n",
    "    auto_approved_count = len([r for r in successful if r.get(\"auto_approved\", False)])\n",
    "\n",
    "    topic_class_dist = defaultdict(int)\n",
    "    for r in successful:\n",
    "        topic_class_dist[r.get(\"topic_class\", \"unknown\")] += 1\n",
    "\n",
    "    completion_states = defaultdict(int)\n",
    "    for r in successful:\n",
    "        completion_states[r.get(\"completion_state\", \"unknown\")] += 1\n",
    "\n",
    "    enrichment_attempts = len([r for r in all_results if r.get(\"attempted_enrichment\")])\n",
    "    enrichment_successes = len([r for r in successful if r.get(\"attempted_enrichment\")])\n",
    "\n",
    "    avg_correctness = sum(r.get(\"correctness_score\", 0) for r in successful) / max(len(successful), 1)\n",
    "    avg_richness = sum(r.get(\"richness_score\", 0) for r in successful) / max(len(successful), 1)\n",
    "\n",
    "    # Print report\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL STATS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"⏱️  Time: {elapsed:.1f}s\")\n",
    "    print(f\"🎬 Processed: {len(all_results)} reels\")\n",
    "    print(f\"✅ Success: {len(successful)} reels\")\n",
    "    print(f\"❌ Errors: {len([r for r in all_results if r['status'] == 'error'])}\")\n",
    "    print(f\"🚫 Rejected: {len([r for r in all_results if r['status'] == 'rejected'])}\")\n",
    "    print()\n",
    "    print(f\"🎴 Cards Generated:\")\n",
    "    print(f\"   Total: {total_cards}\")\n",
    "    print(f\"   Basic: {basic_cards}\")\n",
    "    print(f\"   Cloze: {cloze_cards}\")\n",
    "    print(f\"   Tradeoff: {tradeoff_cards}\")\n",
    "    print()\n",
    "    print(f\"🔄 Duplicates filtered: {total_duplicates}\")\n",
    "    print(f\"⭐ Avg Quality: {avg_quality:.1f}/100\")\n",
    "    print(f\"📊 Avg Confidence: {avg_confidence:.2f}\")\n",
    "    print(f\"🚀 Throughput: {len(all_results)/elapsed:.2f} reels/s\")\n",
    "    print()\n",
    "    print(f\"📊 QUALITY DIMENSIONS:\")\n",
    "    print(f\"   Correctness: {avg_correctness:.2f}/1.0\")\n",
    "    print(f\"   Richness: {avg_richness:.2f}/1.0\")\n",
    "    print()\n",
    "    print(f\"🎯 COMPLETION STATES:\")\n",
    "    for state, count in sorted(completion_states.items()):\n",
    "        pct = (count / len(successful) * 100) if successful else 0\n",
    "        print(f\"   {state}: {count} ({pct:.1f}%)\")\n",
    "    print()\n",
    "    print(f\"📌 Priority Distribution:\")\n",
    "    print(f\"   P0 (≥85): {p0_cards} cards\")\n",
    "    print(f\"   P1 (70-84): {p1_cards} cards\")\n",
    "    print(f\"   P2 (<70): {p2_cards} cards\")\n",
    "    print()\n",
    "    print(f\"📊 Confidence Breakdown:\")\n",
    "    print(f\"   High (≥0.85): {len(high_confidence)} reels — Auto-approved ✅\")\n",
    "    print(f\"   Medium (0.65-0.84): {len(needs_review)} reels — Review needed ⚠️\")\n",
    "    print(f\"   Low (<0.65): {len(low_confidence)} reels — Consider re-prompt 🔄\")\n",
    "    print(f\"   Auto-approved (confidence ≥0.85 AND correctness ≥0.9): {auto_approved_count} reels 🎯\")\n",
    "    print()\n",
    "    print(\"🧠 ADAPTIVE LEARNING STATS\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"🔄 Enrichment attempts: {enrichment_attempts}\")\n",
    "    print(f\"✅ Enrichment successes: {enrichment_successes}\")\n",
    "    if enrichment_attempts > 0:\n",
    "        success_rate = (enrichment_successes / enrichment_attempts) * 100\n",
    "        print(f\"📈 Success rate: {success_rate:.1f}%\")\n",
    "\n",
    "    print(f\"\\n🎯 Prompt Routing Distribution:\")\n",
    "    total_routed = sum(ROUTING_COUNTS.values())\n",
    "    for strategy, count in sorted(ROUTING_COUNTS.items()):\n",
    "        if count > 0:\n",
    "            pct = (count / total_routed * 100) if total_routed > 0 else 0\n",
    "            print(f\"   {strategy}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "    if ROUTING_METRICS.get(\"enriched\", 0) > 0:\n",
    "        print(f\"   Enriched (after initial): {ROUTING_METRICS['enriched']}\")\n",
    "\n",
    "    print(f\"\\n📊 Content Signals Detected:\")\n",
    "    content_signals = {k: v for k, v in ROUTING_METRICS.items() if k.startswith(\"content_signal::\")}\n",
    "    for signal, count in sorted(content_signals.items()):\n",
    "        print(f\"   {signal.replace('content_signal::', '')}: {count}\")\n",
    "    \n",
    "    print(f\"\\n🚀 PHASE 1-3 ENHANCEMENTS:\")\n",
    "    print(f\"=\" * 60)\n",
    "    \n",
    "    density_metrics = {k: v for k, v in ROUTING_METRICS.items() if k.startswith(\"content_density::\")}\n",
    "    if density_metrics:\n",
    "        print(f\"📊 Content Density Distribution:\")\n",
    "        for density, count in sorted(density_metrics.items()):\n",
    "            print(f\"   {density.replace('content_density::', '').upper()}: {count} reels\")\n",
    "    \n",
    "    if ROUTING_METRICS.get(\"content_signal::transcript_normalized\", 0) > 0:\n",
    "        normalized_count = ROUTING_METRICS[\"content_signal::transcript_normalized\"]\n",
    "        avg_delta = ROUTING_METRICS.get(\"content_signal::normalization_delta_avg\", 0)\n",
    "        print(f\"\\n📝 Transcript Normalization:\")\n",
    "        print(f\"   Normalized: {normalized_count} transcripts\")\n",
    "        print(f\"   Avg delta: {avg_delta:.0f} chars\")\n",
    "    \n",
    "    print(f\"\\n⚙️  Feature Status:\")\n",
    "    print(f\"   Content Filtering: {'✅' if CONFIG.get('ENABLE_CONTENT_FILTERING') else '❌'}\")\n",
    "    print(f\"   Transcript Normalization: {'✅' if CONFIG.get('ENABLE_TRANSCRIPT_NORMALIZATION') else '❌'}\")\n",
    "    print(f\"   Hybrid Routing: {'✅' if CONFIG.get('ENABLE_HYBRID_ROUTING') else '❌'}\")\n",
    "    print(f\"=\" * 60)\n",
    "\n",
    "    if rejection_memory:\n",
    "        mem_stats = rejection_memory.get_stats()\n",
    "        print(f\"\\n🧠 Rejection memory:\")\n",
    "        print(f\"   Concepts tracked: {mem_stats['total_concepts']}\")\n",
    "        print(f\"   Total rejections: {mem_stats['total_rejections']}\")\n",
    "        if mem_stats['strategies']:\n",
    "            print(f\"   Strategies learned:\")\n",
    "            for strategy, count in mem_stats['strategies'].items():\n",
    "                print(f\"     - {strategy}: {count} concepts\")\n",
    "        if 'learning_velocity' in mem_stats:\n",
    "            lv = mem_stats['learning_velocity']\n",
    "            print(f\"   Learning velocity:\")\n",
    "            print(f\"     - Avg attempts to success: {lv['avg_attempts_until_success']}\")\n",
    "            print(f\"     - Concepts learned: {lv['concepts_learned']}\")\n",
    "            print(f\"     - Still learning: {lv['concepts_still_learning']}\")\n",
    "\n",
    "    term_stats = terminal_rejections.get_stats()\n",
    "    if term_stats['total'] > 0:\n",
    "        print(f\"\\n🚫 Terminal Rejections (never retry):\")\n",
    "        print(f\"   Total: {term_stats['total']}\")\n",
    "        print(f\"   By stage:\")\n",
    "        for stage, count in sorted(term_stats['by_stage'].items()):\n",
    "            print(f\"     - {stage}: {count}\")\n",
    "        if term_stats['by_reason']:\n",
    "            print(f\"   Top reasons:\")\n",
    "            sorted_reasons = sorted(term_stats['by_reason'].items(), key=lambda x: x[1], reverse=True)\n",
    "            for reason, count in sorted_reasons[:5]:\n",
    "                print(f\"     - {reason}: {count}\")\n",
    "\n",
    "    print(f\"\\n📚 Topic Class Distribution:\")\n",
    "    for topic_class, count in sorted(topic_class_dist.items()):\n",
    "        print(f\"   {topic_class}: {count} reels\")\n",
    "\n",
    "    if PROMPT_VERSION_STATS:\n",
    "        print(f\"\\n🔄 PROMPT VERSION LIFECYCLE:\")\n",
    "        print(\"-\" * 60)\n",
    "        sorted_versions = sorted(\n",
    "            PROMPT_VERSION_STATS.items(),\n",
    "            key=lambda x: x[1].get(\"attempts\", 0),\n",
    "            reverse=True\n",
    "        )[:10]\n",
    "        for version, stats in sorted_versions:\n",
    "            status = \"🚫 DEPRECATED\" if stats.get(\"deprecated\") else \"✅\"\n",
    "            print(f\"   {status} {version[:40]:40s} | \"\n",
    "                  f\"attempts: {stats['attempts']:3d} | \"\n",
    "                  f\"success: {stats['success_rate']:5.1%}\")\n",
    "\n",
    "        save_prompt_version_stats(PROMPT_VERSION_STATS)\n",
    "        print(f\"   💾 Saved to: {PROMPT_VERSION_FILE}\")\n",
    "\n",
    "    print(f\"\\n📁 Output: {output_file}\")\n",
    "    if needs_review:\n",
    "        print(f\"⚠️  Review: {CONFIG['OUT_DIR']}/needs_review.json\")\n",
    "    print(f\"🔍 Fingerprints: {len(duplicate_detector.fingerprints)} unique cards\")\n",
    "\n",
    "    if BLOOM_AVAILABLE:\n",
    "        bloom_stats = duplicate_detector.get_bloom_stats()\n",
    "        print(f\"🌸 Bloom filter: {bloom_stats['false_positives']}/{bloom_stats['total_checks']} FP ({bloom_stats['fp_rate_pct']:.3f}%)\")\n",
    "        if bloom_stats['needs_rebuild']:\n",
    "            print(f\"   ⚠️  WARNING: Bloom filter saturated (>1% FP rate) - rebuilding...\")\n",
    "            duplicate_detector.rebuild_bloom_if_needed()\n",
    "\n",
    "    if rejection_memory:\n",
    "        print(f\"🧠 Rejection memory: {REJECTION_MEMORY_FILE}\")\n",
    "    terminal_rejections.save()\n",
    "    print(f\"🚫 Terminal rejections: {TERMINAL_REJECTIONS_FILE}\")\n",
    "    if PROMPT_VERSION_STATS:\n",
    "        print(f\"🔄 Prompt versions: {PROMPT_VERSION_FILE}\")\n",
    "    print(f\"📊 Routing metrics: {ROUTING_METRICS_FILE}\")\n",
    "    print(\"\\n✅ DONE\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⚠️  Interrupted - saving state...\")\n",
    "        duplicate_detector.save_if_dirty(force=True)\n",
    "        progress_tracker.flush()\n",
    "        if rejection_memory:\n",
    "            rejection_memory.save()\n",
    "        terminal_rejections.save()\n",
    "        save_prompt_version_stats(PROMPT_VERSION_STATS)\n",
    "\n",
    "        try:\n",
    "            with open(ROUTING_METRICS_FILE, 'w') as f:\n",
    "                json.dump(dict(ROUTING_METRICS), f, indent=2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        sys.exit(0)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\n❌ ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        duplicate_detector.save_if_dirty(force=True)\n",
    "        if rejection_memory:\n",
    "            rejection_memory.save()\n",
    "        save_prompt_version_stats(PROMPT_VERSION_STATS)\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
